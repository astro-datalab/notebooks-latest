{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b523a-8833-4c1f-98e3-d7620baaf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'David Herrera <david.herrera@noirlab.edu>, and the Astro Data Lab Team <datalab@noirlab.edu>'\n",
    "__version__ = '20250106' # yyyymmdd\n",
    "__datasets__ = ['ls_dr6','ls_dr7','ls_dr8','ls_dr9']\n",
    "__keywords__ = ['extragalactic','galaxies','joint query','legacy survey','desi']\n",
    "__nbid__ = 'nb0068'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32f8b3-d29f-46e8-be76-fe92cd14fcea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DESI Legacy Imaging Survey (LIS) \n",
    "## Coverage, Magnitudes and comparison with AllWISE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe704271-8e37-4f2a-8ed9-63e362b1ea35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table of contents\n",
    "* [Goals & Summary](#goals)\n",
    "* [Disclaimer & attribution](#attribution)\n",
    "* [Imports & setup](#import)\n",
    "* [Survey Coverage](#Fig2)\n",
    "* [Forced mid-infrared photometry](#Fig8)\n",
    "* [Depth distribution of point sources](#Fig15)\n",
    "* [Color-color Distribution by Type of Extended Objects](#Fig16)\n",
    "* [Resources and References](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01de8b8-6776-456f-8d3c-bf06475155d5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "# Goals\n",
    "* Reproduce plots published in the DESI LIS overview paper (Dey et al., 2019) using tables we were or are serving in our Data Lab database and resources in our Data Lab service. We'll be using in particular the datasets DESI Legacy Survey DR6, DR7, DR8.\n",
    "* Compare some of them with the latest, most stable data releases. DR9 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc5486-7623-4a62-93e0-68d118a2df86",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "**Background**\n",
    "\n",
    "We wanted to reproduce science results obtained in a published and refereed paper that has used datasets that are included and openly serviced by Data Lab. We settled in this one that has used datasets from 2019.\n",
    "\n",
    "**Data retrieval**\n",
    "We used catalogs from the DESI Legacy Imaging Survey DR6, DR7 (both retired), DR8 & DR9 (the latest more complete and stable DR) in order to update and compare results.\n",
    "\n",
    "In this Notebook, we take on the mission to recreate 4 plots that were published in the paper \"Overview of the DESI Legacy Imaging Surveys\" (Dey et al, AJ, 2019) using our Data Lab database, where the catalogs eventually used for these figures are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c17d5f-20cf-4b11-b0bd-a6172582923b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"attribution\"></a>\n",
    "# Disclaimer & attribution\n",
    "\n",
    "Disclaimers\n",
    "-----------\n",
    "Note that using the Astro Data Lab constitutes your agreement with our minimal [Disclaimers](https://datalab.noirlab.edu/disclaimers.php).\n",
    "\n",
    "Acknowledgments\n",
    "---------------\n",
    "If you use **Astro Data Lab** in your published research, please include the text in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the Astro Data Lab, which is part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "If you use **SPARCL jointly with the Astro Data Lab platform** (via JupyterLab, command-line, or web interface) in your published research, please include this text below in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the SPectra Analysis and Retrievable Catalog Lab (SPARCL) and the Astro Data Lab, which are both part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "In either case **please cite the following papers**:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Astro Data Lab overview: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411\n",
    "\n",
    "If you are referring to the Data Lab JupyterLab / Jupyter Notebooks, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097\n",
    "\n",
    "If publishing in a AAS journal, also add the keyword: `\\facility{Astro Data Lab}`\n",
    "\n",
    "And if you are using SPARCL, please also add `\\software{SPARCL}` and cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576\n",
    "\n",
    "The NOIRLab Library maintains [lists of proper acknowledgments](https://noirlab.edu/science/about/scientific-acknowledgments) to use when publishing papers using the Lab's facilities, data, or services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7ac07-06fb-4dad-832e-f65108fbe864",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import\"></a>\n",
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32456e-c730-4a17-8b0f-4cdfe5616611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std lib\n",
    "from getpass import getpass\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "\n",
    "# Data Lab\n",
    "from dl import queryClient as qc\n",
    "from dl import authClient as ac\n",
    "\n",
    "print('Done importing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96841197-4e51-4bce-8b11-0ed110218e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next 3 lines in case authentication is needed:\n",
    "token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\n",
    "if not ac.isValidToken(token):\n",
    "    raise Exception('Token is not valid. Please check your usename/password and execute this cell again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829dcb0d-a32a-4e91-aee0-701f15d28dd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"Fig2\"></a>\n",
    "## Fig. 2 - Image coverage of the DESI Legacy Imaging Surveys\n",
    "Figure 2 consists of an all-sky map of the coverage of the DESI LIS. We use the data from the DR8 to build a map with what is contained in that data release, by considering the size and number of bricks and adding them onto the all-sky map. DR7 does not contain the northern part of the LIS (from the MLzS & BASS surveys)\n",
    "\n",
    "We created a csv file out of the tractor table of ls_dr8 that can be re-created by running this query in the PSQL prompt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474a5ee-eb17-43d5-8a1b-14c3fe0f2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_fig2 = (\"\"\"\n",
    "# SELECT avg(ra) as ra0, avg(dec) as dec0, nest4096, count(nest4096) as n\n",
    "# FROM ls_dr8.tractor GROUP BY nest4096\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b19c5d-7a10-4aa6-b35f-1bb45fd920bf",
   "metadata": {},
   "source": [
    "or by running an asyncronous query with the query client, for example, in the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc80692-a440-465e-a0f9-f16a74c01925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog = qc.query(sql=query_fig2, async=True, fmt='pandas')\n",
    "# Saving the data frame to a csv file with header:\n",
    "# table = catalog.to_csv('catalog.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac392e0a-9350-40f2-bb81-89b6910e6b4f",
   "metadata": {},
   "source": [
    "which will take several hours and you can later save it in your mydb space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb757e4-00a9-45f6-9ad3-4ee5c6c591ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T21:39:19.858045Z",
     "iopub.status.busy": "2023-09-08T21:39:19.857357Z",
     "iopub.status.idle": "2023-09-08T21:39:19.865867Z",
     "shell.execute_reply": "2023-09-08T21:39:19.864557Z",
     "shell.execute_reply.started": "2023-09-08T21:39:19.857974Z"
    }
   },
   "source": [
    "The query can not be run or the file created in our notebooks since it takes several hours and the returned table file is very large (4.6GB) to be kept around.\n",
    "So before plotting, we will save the actual map data into a fits table which can be read and the map reproduced by using its data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7eba59-e9dc-42f7-ba28-97bdc3703794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T18:09:20.775788Z",
     "iopub.status.busy": "2023-09-12T18:09:20.775323Z",
     "iopub.status.idle": "2023-09-12T18:09:21.492442Z",
     "shell.execute_reply": "2023-09-12T18:09:21.490964Z",
     "shell.execute_reply.started": "2023-09-12T18:09:20.775747Z"
    }
   },
   "source": [
    "We defined next a couple of functions for the manipulation of data that goes into making the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497da44-2c62-43eb-9717-23a2bfe10131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS AND THE FOLLOWING 2 CELLS in case you are getting the query via the queryClient \n",
    "# or you are reading the data from the csv file\n",
    "#def compute_survey_area(df,res=12):\n",
    "#    areasky = ((360*u.deg)**2)/np.pi\n",
    "#    nside = 2**res\n",
    "#    npix = 12*nside**2\n",
    "#    areapix = areasky / npix\n",
    "#    areasurvey = df.shape[0]*areapix\n",
    "#    return areapix, areasurvey\n",
    "\n",
    "#def compute_healpix_map(df,areapix,newnside=None):\n",
    "#    tmap = np.zeros(hp.nside2npix(4096))\n",
    "#    tmap[df['nest4096']] = df['n']/areapix\n",
    "#    if newnside is not None:     \n",
    "#        tmap = hp.ud_grade(tmap,newnside,order_in='NESTED',order_out='NESTED')\n",
    "#    return tmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe4ab0-df56-4368-bbfe-1ed99331cebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T18:43:34.783232Z",
     "iopub.status.busy": "2023-09-12T18:43:34.782559Z",
     "iopub.status.idle": "2023-09-12T18:43:50.920219Z",
     "shell.execute_reply": "2023-09-12T18:43:50.918753Z",
     "shell.execute_reply.started": "2023-09-12T18:43:34.783174Z"
    }
   },
   "source": [
    "We would now read the data either from the large file created with the query above or from the smaller file containing the actual map data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05900f2-2b2c-438a-8fca-a8ce1c15ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was the csv from where the map data was taken. It is too big (4.6 GB) to be\n",
    "# kept around.\n",
    "# df = pd.read_csv('/dlusers/davalfher/notebooks/NewScienceCase/dataDR8_fig2.csv',usecols=['nest4096','n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fe99c-2899-4b8d-9434-d5967ef2cadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we compute the actual map after the csv was read\n",
    "# areapix, areasurvey = compute_survey_area(df)\n",
    "\n",
    "# m = compute_healpix_map(df,areapix,newnside=2048);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd20b05-d802-4c04-bcc7-8c15ae199921",
   "metadata": {},
   "source": [
    "If we already have the healpy fits file already saved, we read the data from it next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc5282-8cf4-4287-97de-43e83190ff60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store the map data in healpy fits it case it doesn't exist yet, \n",
    "# so it can be read later from this much smaller file.\n",
    "# Uncomment the next line and run the cell if you haven't saved it yet\n",
    "#\n",
    "# hp.write_map(\"map_fig2.fits\", m, overwrite=True)\n",
    "# If the healpy map data has been saved already, uncomment the next line and run this cell:\n",
    "m = hp.read_map(\"map_fig2.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4490be-ed0c-4c65-8ff4-0ce218cb7f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T18:43:34.783232Z",
     "iopub.status.busy": "2023-09-12T18:43:34.782559Z",
     "iopub.status.idle": "2023-09-12T18:43:50.920219Z",
     "shell.execute_reply": "2023-09-12T18:43:50.918753Z",
     "shell.execute_reply.started": "2023-09-12T18:43:34.783174Z"
    },
    "tags": []
   },
   "source": [
    "Now, we finally plot our map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a0ea9-76b8-4ca5-a6aa-f8f5087a48de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we plot the map\n",
    "fig2 = hp.projview(m, \n",
    "            projection_type='mollweide',\n",
    "            rot=(-90,0,0),coord='C',\n",
    "            nest=True,\n",
    "            cmap='Blues',\n",
    "            graticule=True,\n",
    "            graticule_labels=True,\n",
    "            custom_xtick_labels=[\"30\",\"330\",\"270\",\"210\",\"150\"],\n",
    "            unit=r'Object Density per Healpixel'\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acd358-e548-4b8c-bc9c-5326d74167c2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Fig8\"></a>\n",
    "## Fig. 8 - LS and Wise mid-infrared (W1) comparisons \n",
    "\n",
    "The Legacy Survey obtains forced photometry with [The Tractor](https://thetractor.org/about/) code. In the following plot, we compare it to the WISE photometry.\n",
    "\n",
    "First, we obtain and manipulate the data for the left side of the plot \n",
    "#### LS W1 vs AllWISE W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cbc2-8c57-4c8e-bf22-bc7087937888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query to obtain necessary data by crossmatching both LS and AllWISE catalogs. \n",
    "# The photometry in LS and AllWise use different reference system. \n",
    "# Legacy Survey uses AB and AllWISE uses Vega, so we do the corresponding conversion \n",
    "# in the query itself:\n",
    "# **IMPORTANT NOTE:** You have to run this cell and the following one a few times, and each time, \n",
    "# increase the LIMIT parameter in the query by around 30K until you reach around 150K-170K and \n",
    "# the data retrieval takes less than the maximum allowed time of 5 minutes. \n",
    "# The reason for that is \n",
    "# 1) The postgreSQL cache will reduce the time on each query run and\n",
    "# 2) we want the largest possible sample for better plots\n",
    "qc.set_profile('db03')\n",
    "\n",
    "query_fig8 = (\"\"\"\n",
    "select a.designation,l.ra, l.dec, l.mag_w1 - 2.699 as mag_w1, l.random_id as random_id, \n",
    "a.w1mpro as w1mpro\n",
    "from nbdata.nb0068_lsdr7_tractor as l, allwise.source as a\n",
    "where q3c_radial_query(a.ra,a.dec,l.ra,l.dec,1/3600.) \n",
    "AND l.ra BETWEEN 120 AND 250\n",
    "AND l.random_id between 45 and 65 \n",
    "limit 50000\n",
    "\"\"\")\n",
    "\n",
    "print (query_fig8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15417bfd-cf34-4765-9200-4248a889c458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T19:03:34.782072Z",
     "iopub.status.busy": "2023-09-12T19:03:34.781483Z",
     "iopub.status.idle": "2023-09-12T19:11:47.703954Z",
     "shell.execute_reply": "2023-09-12T19:11:47.702596Z",
     "shell.execute_reply.started": "2023-09-12T19:03:34.782019Z"
    }
   },
   "source": [
    "Retrieve the data using the pandas data handling tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79330769-9f70-4ee8-9279-211c50044a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(data_awls)\n",
    "# Fetch the W1 mag from nbdata.nb0068_lsdr7.tractor and from allwise.source\n",
    "# Change the dbXX to the one you can use (db01 or db03)\n",
    "#qc.set_profile('db01')\n",
    "w1_awls = qc.query(sql=query_fig8, fmt='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebb34f-f2d2-4330-a052-b10c3a7ca75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking first and last rows of the retrieved table:\n",
    "w1_awls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13494a3d-3e60-4dc6-bcb4-ea562306ec91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-16T02:08:05.015922Z",
     "iopub.status.busy": "2023-09-16T02:08:05.015345Z",
     "iopub.status.idle": "2023-09-16T02:08:05.151948Z",
     "shell.execute_reply": "2023-09-16T02:08:05.150764Z",
     "shell.execute_reply.started": "2023-09-16T02:08:05.015869Z"
    }
   },
   "source": [
    "We need to clean the data from undetermined values in the form of infinities and NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56e463-abb0-4336-a23b-52e2e4bd2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean Inf and NaN values and reset indexes in dataframe:\n",
    "\n",
    "def clean_infnan(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "\n",
    "data_awls = clean_infnan (w1_awls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9b437-12c3-4263-bb2e-1847b0deb365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-16T02:08:15.078917Z",
     "iopub.status.busy": "2023-09-16T02:08:15.078360Z",
     "iopub.status.idle": "2023-09-16T02:08:15.105847Z",
     "shell.execute_reply": "2023-09-16T02:08:15.104684Z",
     "shell.execute_reply.started": "2023-09-16T02:08:15.078867Z"
    }
   },
   "source": [
    "We check that some rows must have been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada63cc3-696e-4ff9-947f-a15b44c3b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_awls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c1e8f8-a677-4350-b188-14643087b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the next lines in case the data is not saved in a file already\n",
    "# Saving the data frame to a csv file with header:\n",
    "# table = data_awls.to_csv('data_fig8.csv', encoding='utf-8', index=False)\n",
    "# data_awls = Table.read('data_fig8.csv')\n",
    "# Next we'll read the table downloaded from the IRSA query tool.\n",
    "# data_awls2 = Table.read('table2.vot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467b344-37c7-42a9-acd5-d6b3ff5d746c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-16T02:08:15.078917Z",
     "iopub.status.busy": "2023-09-16T02:08:15.078360Z",
     "iopub.status.idle": "2023-09-16T02:08:15.105847Z",
     "shell.execute_reply": "2023-09-16T02:08:15.104684Z",
     "shell.execute_reply.started": "2023-09-16T02:08:15.078867Z"
    }
   },
   "source": [
    "We are done with the data frame for the left side panel.\n",
    "\n",
    "Now we obtain and manipulate the data for the right side panel.\n",
    "\n",
    "#### Number of sources in LS vs AllWISE\n",
    "\n",
    "We set the query for LS data by choosing a box small enough in the sky for the queries not to time out (< 300s) but big enough to have plenty of sources in both datasets, of around 200<sup>2</sup> &deg;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fcb01-3f85-4328-9ad0-8f05307fad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fig8a = (\"\"\"\n",
    "select ra, dec, mag_w1\n",
    "from nbdata.nb0068_lsdr7_tractor\n",
    "where ra BETWEEN 150 AND 170 AND\n",
    "dec between 0 and 10\n",
    "\"\"\")\n",
    "print(query_fig8a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f26c8e-99e5-4fbd-99c0-d4997ec6f4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T16:47:51.664228Z",
     "iopub.status.busy": "2023-10-02T16:47:51.663610Z",
     "iopub.status.idle": "2023-10-02T16:47:51.672780Z",
     "shell.execute_reply": "2023-10-02T16:47:51.671107Z",
     "shell.execute_reply.started": "2023-10-02T16:47:51.664173Z"
    }
   },
   "source": [
    "We estbalished the server db01 to query the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c63df-bdd4-4467-91fa-fcea92d5e95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qc.set_profile('db03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803abb8-951a-4443-bafb-d9702b27c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_awls)\n",
    "# Fetch the W1 mag from nbdata.nb0068_lsdr7.tractor \n",
    "ls_w1 = qc.query(sql=query_fig8a, fmt='pandas')\n",
    "ls_w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653f9c2-d00c-45eb-b96a-e6218905ae9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-16T02:08:05.015922Z",
     "iopub.status.busy": "2023-09-16T02:08:05.015345Z",
     "iopub.status.idle": "2023-09-16T02:08:05.151948Z",
     "shell.execute_reply": "2023-09-16T02:08:05.150764Z",
     "shell.execute_reply.started": "2023-09-16T02:08:05.015869Z"
    }
   },
   "source": [
    "We need to clean the data from undetermined values in the form of infinities and NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb9f21-6216-4a4d-b801-88355e6d82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Inf and NaN values:\n",
    "clean_infnan (ls_w1)\n",
    "\n",
    "# How many rows are left after clean up:\n",
    "len_lsw1 = len(ls_w1)\n",
    "\n",
    "len_lsw1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd746c52-cfc0-44e4-a416-807d607b85b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T03:55:17.649311Z",
     "iopub.status.busy": "2023-09-30T03:55:17.648679Z",
     "iopub.status.idle": "2023-09-30T03:55:17.658621Z",
     "shell.execute_reply": "2023-09-30T03:55:17.657270Z",
     "shell.execute_reply.started": "2023-09-30T03:55:17.649252Z"
    }
   },
   "source": [
    "We determine what is the lowest and highest Declination of the LS sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ae046-60d8-4990-b88b-111c0410b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We determine the max and min Declination of the LS sample we queried, \n",
    "# to use it as limits for the AllWISE sample\n",
    "dhi = ls_w1['dec'].max()\n",
    "dlo = ls_w1['dec'].min()\n",
    "print(dlo)\n",
    "print(dhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ef2bf-a081-44e7-a5b3-46f426ce66d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T03:55:17.649311Z",
     "iopub.status.busy": "2023-09-30T03:55:17.648679Z",
     "iopub.status.idle": "2023-09-30T03:55:17.658621Z",
     "shell.execute_reply": "2023-09-30T03:55:17.657270Z",
     "shell.execute_reply.started": "2023-09-30T03:55:17.649252Z"
    }
   },
   "source": [
    "Based on these, we define the query and search box in the AllWISE survey\n",
    "\n",
    "We now pull data from the AllWISE source catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e140630-896d-4268-bd48-50b5fb1c30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fig8b = (\"\"\"\n",
    "select designation,a.ra as raaw,a.dec as decaw,w1mpro\n",
    "from allwise.source as a\n",
    "where a.ra BETWEEN 150 AND 170\n",
    "AND a.dec BETWEEN %s AND %s\n",
    "limit %s\n",
    "\"\"\") % (dlo,dhi,len_lsw1)\n",
    "print(query_fig8b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1678af-de97-4004-b57d-c26333170569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the W1 mag from allwise.source\n",
    "aw_w1mpro = qc.query(sql=query_fig8b, fmt='pandas')\n",
    "aw_w1mpro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ceb470-4d86-4648-b7cd-9f8ca7bc10c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T03:55:17.649311Z",
     "iopub.status.busy": "2023-09-30T03:55:17.648679Z",
     "iopub.status.idle": "2023-09-30T03:55:17.658621Z",
     "shell.execute_reply": "2023-09-30T03:55:17.657270Z",
     "shell.execute_reply.started": "2023-09-30T03:55:17.649252Z"
    }
   },
   "source": [
    "AllWISE happens to not have 'Inf' or 'NaN' in their magnitude columns, so we don't need to clean up the sample.\n",
    "\n",
    "Once we are happy with our samples, we finally plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f33c0-492a-4984-8627-97a63e2d0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#font = {'size'   : 22}\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 8))\n",
    "plt.subplots_adjust(wspace = 0.18, hspace = 0.18)\n",
    "\n",
    "#LEFT side:\n",
    "x_fig8a = data_awls['w1mpro']\n",
    "y_fig8a = data_awls['mag_w1']\n",
    "axs[0].axline([0,0], c='black', slope=1, linewidth=0.2)\n",
    "axs[0].hist2d(x_fig8a,y_fig8a, bins=(300,300), norm = colors.LogNorm(), cmap = plt.cm.Greys)\n",
    "axs[0].set_xlim(19.,5.)\n",
    "axs[0].set_ylim(19,5.)\n",
    "axs[0].set(xlabel='AllWISE W1 mag', ylabel='Legacy Survey Forced-Photometry W1 mag');\n",
    "\n",
    "# RIGHT side:\n",
    "my_bins2 = np.arange(10.,23.0001,0.1)\n",
    "# We have to correct LS magnitude to get in the same reference\n",
    "w1mag,bins = np.histogram(ls_w1['mag_w1']-2.699, bins=my_bins2,range = (10., 23.))\n",
    "aw1mag,bins = np.histogram(aw_w1mpro['w1mpro'], bins=my_bins2,range = (10., 23.))\n",
    "centers = (my_bins2[0:-1]+my_bins2[1:])/2\n",
    "axs[1].set(xlabel='W1 Magnitude', ylabel='Number of sources')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlim(10.,23.)\n",
    "axs[1].set_ylim(10,1.5E6)\n",
    "\n",
    "axs[1].plot(centers,w1mag, c='cyan', drawstyle='steps', label='LegacySurvey Forced', lw=5.0, ls='-')\n",
    "axs[1].plot(centers,aw1mag, c='blue', drawstyle='steps',label='DataLab AllWISE Catalog', lw=0.8);\n",
    "axs[1].legend(loc=3,frameon=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af50ef-085d-4043-88c9-dfa75cce9207",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Fig15\"></a>\n",
    "\n",
    "## Fig. 15 - Depth distribution of point sources\n",
    "Now we are going to calculate the depth for each band _grz_ in DR6 and DR7 made in the original paper, and then will compare with those from DR9.\n",
    "\n",
    "First, we build the queries to obtain the data from those 3 datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1b3bd-f155-48d1-b76d-cf9d6bfd609b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Requires a minimun number of objects:\n",
    "nmin = 1000\n",
    "# Requires 90% of the image are to contain  >= 3 exposures:\n",
    "npix = 0.9*900.*900. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a9b69-b7c1-4327-8534-f463c4606e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_colnames(band,cols=(1,2,3,4,5,6)):\n",
    "    pattern = 'nexphist_%s_%d'\n",
    "    colnames = [pattern % (band,col) for col in cols]\n",
    "    return colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd253e35-5e10-4804-a2a9-08953acbbbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_query(table='nbdata.nb0068_lsdr6_bricks_dr6',band='g'):\n",
    "    colsall = '+'.join(get_colnames(band,(1,2,3,4,5,6)))\n",
    "    colsgt3 = '+'.join(get_colnames(band,(4,5,6)))\n",
    "    \n",
    "    q =\\\n",
    "    \"\"\"SELECT psfdepth_g as psfdepth FROM\n",
    "         (SELECT *, t1.sumgt3 / NULLIF(t1.sumall,0.) as frac FROM\n",
    "           (SELECT nexp_%s, psfdepth_%s, nobjs, %s as sumall, %s as sumgt3 FROM %s) AS t1\n",
    "            WHERE nexp_%s >= 3\n",
    "            AND nobjs >= %d\n",
    "            AND sumall > %d) AS t2\n",
    "         WHERE frac > 0.9\n",
    "    \"\"\" % (band,band,colsall,colsgt3,table,band,nmin,npix)\n",
    "    print(q)\n",
    "\n",
    "    df = qc.query(q,fmt='pandas')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4044fbb-4f4e-41bd-b66b-7b85be52fe52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d6a = run_query(table='nbdata.nb0068_lsdr6_bricks_dr6',band='g')\n",
    "d7a = run_query(table='nbdata.nb0068_lsdr7_bricks_dr7',band='g')\n",
    "d9a = run_query(table='ls_dr9.bricks_s',band='g')\n",
    "\n",
    "#d6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d52913-885d-4c54-87c0-768f3d1281d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: THESE ARE THE QUERIES USED TO PULL THE DATA FROM THE DATABASE BUT\n",
    "# IT SHOULD BE COMMENTED OUT AND LEFT AS SUCH SINCE THESE TABLES WILL NOT BE\n",
    "# SERVICED ANY MORE BY DATALAB (EXCEPT FOR query15c FOR ls_dr9)\n",
    "\n",
    "query15a = (\"\"\"SELECT \n",
    "ra as d6ra,dec as d6dec , nexp_g as d6neg, nexp_r as d6ner, nexp_z as d6nez,\n",
    "nexphist_g_1 as d6ng1,nexphist_g_2 as d6ng2,nexphist_g_3 as d6ng3,nexphist_g_4 as d6ng4,nexphist_g_5 as d6ng5,nexphist_g_6 as d6ng6,\n",
    "nexphist_r_1 as d6nr1,nexphist_r_2 as d6nr2,nexphist_r_3 as d6nr3,nexphist_r_4 as d6nr4,nexphist_r_5 as d6nr5,nexphist_r_6 as d6nr6,\n",
    "nexphist_z_1 as d6nz1,nexphist_z_2 as d6nz2,nexphist_z_3 as d6nz3,nexphist_z_4 as d6nz4,nexphist_z_5 as d6nz5,nexphist_z_6 as d6nz6,\n",
    "psfdepth_g as d6psfdg,psfdepth_r as d6psfdr,psfdepth_z as d6psfdz,\n",
    "nobjs\n",
    "FROM nbdata.nb0068_lsdr6_bricks_dr6 as d6b\"\"\")\n",
    "#print(query15a)\n",
    "query15b = (\"\"\"SELECT \n",
    "ra as d7ra,dec as d7dec , nexp_g as d7neg, nexp_r as d7ner, nexp_z as d7nez,\n",
    "nexphist_g_1 as d7ng1,nexphist_g_2 as d7ng2,nexphist_g_3 as d7ng3,nexphist_g_4 as d7ng4,nexphist_g_5 as d7ng5,nexphist_g_6 as d7ng6,\n",
    "nexphist_r_1 as d7nr1,nexphist_r_2 as d7nr2,nexphist_r_3 as d7nr3,nexphist_r_4 as d7nr4,nexphist_r_5 as d7nr5,nexphist_r_6 as d7nr6,\n",
    "nexphist_z_1 as d7nz1,nexphist_z_2 as d7nz2,nexphist_z_3 as d7nz3,nexphist_z_4 as d7nz4,nexphist_z_5 as d7nz5,nexphist_z_6 as d7nz6,\n",
    "psfdepth_g as d7psfdg,psfdepth_r as d7psfdr,psfdepth_z as d7psfdz,\n",
    "nobjs\n",
    "FROM nbdata.nb0068_lsdr7_bricks_dr7 as d7b\"\"\")\n",
    "#print(query15b)\n",
    "query15c = (\"\"\"SELECT\n",
    "ra as d9ra,dec as d9dec , nexp_g as d9neg, nexp_r as d9ner, nexp_z as d9nez,\n",
    "nexphist_g_1 as d9ng1,nexphist_g_2 as d9ng2,nexphist_g_3 as d9ng3,nexphist_g_4 as d9ng4,nexphist_g_5 as d9ng5,nexphist_g_6 as d9ng6,\n",
    "nexphist_r_1 as d9nr1,nexphist_r_2 as d9nr2,nexphist_r_3 as d9nr3,nexphist_r_4 as d9nr4,nexphist_r_5 as d9nr5,nexphist_r_6 as d9nr6,\n",
    "nexphist_z_1 as d9nz1,nexphist_z_2 as d9nz2,nexphist_z_3 as d9nz3,nexphist_z_4 as d9nz4,nexphist_z_5 as d9nz5,nexphist_z_6 as d9nz6,\n",
    "psfdepth_g as d9psfdg,psfdepth_r as d9psfdr,psfdepth_z as d9psfdz,\n",
    "nobjs\n",
    "FROM ls_dr9.bricks_s as d9b\"\"\")\n",
    "print(query15c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61821312-54ca-43a8-a5ea-fa98cde04148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:20:14.022659Z",
     "iopub.status.busy": "2023-09-15T04:20:14.022031Z",
     "iopub.status.idle": "2023-09-15T04:20:14.031887Z",
     "shell.execute_reply": "2023-09-15T04:20:14.030406Z",
     "shell.execute_reply.started": "2023-09-15T04:20:14.022590Z"
    }
   },
   "source": [
    "We run the queries to obtain the data from the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ce19d-9e41-458e-b17c-c0f57cb4ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the DESI LIS data from nbdata.nb0068_lsdr6.bricks_dr6 (d6), nbdata.nb0068_lsdr7.bricks_dr7 (d7)\n",
    "# and ls_dr9.bricks_s (d9):\n",
    "d6 = qc.query(sql=query15a, fmt='pandas')\n",
    "d7 = qc.query(sql=query15b, fmt='pandas')\n",
    "d9 = qc.query(sql=query15c, fmt='pandas')\n",
    "\n",
    "# Uncomment these next 3 lines in case the data has not been save to files yet\n",
    "# d6.to_csv('data_fig15a.csv', encoding='utf-8', index=False)\n",
    "# d7.to_csv('data_fig15b.csv', encoding='utf-8', index=False)\n",
    "# d9.to_csv('data_fig15c.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef857f-cb9c-4b1a-b1ee-6624d19ceea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:32.090272Z",
     "iopub.status.busy": "2023-09-15T04:21:32.089654Z",
     "iopub.status.idle": "2023-09-15T04:21:32.096449Z",
     "shell.execute_reply": "2023-09-15T04:21:32.095085Z",
     "shell.execute_reply.started": "2023-09-15T04:21:32.090216Z"
    }
   },
   "source": [
    "There are 2 conditions established by the authors: \n",
    "\n",
    "1) The minimun number of counts should be 1000, and\n",
    "2) That 90% of the image should be expose 3 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ad2ef-7efe-4b24-87e7-eba68791d2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Requires a minimun number of objects:\n",
    "nmin = 1000\n",
    "# Requires 90% of the image are to contain  >= 3 exposures:\n",
    "npix = 0.9*900.*900. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba283358-6036-44b0-bdb8-91500614fec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:35.132470Z",
     "iopub.status.busy": "2023-09-15T04:21:35.131819Z",
     "iopub.status.idle": "2023-09-15T04:21:35.204198Z",
     "shell.execute_reply": "2023-09-15T04:21:35.202869Z",
     "shell.execute_reply.started": "2023-09-15T04:21:35.132411Z"
    }
   },
   "source": [
    "Now we add up __ALL__ the histograms of pixels per brick per band _g,r,z_ in each of the datasets \n",
    "DR6, DR7 and we want to compare them to the latest, more complete DR9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118aee3-22de-407a-8226-70e833ff6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ng6 = d6['d6ng1'] + d6['d6ng2'] + d6['d6ng3'] + d6['d6ng4'] + d6['d6ng5'] + d6['d6ng6']\n",
    "total_nr6 = d6['d6nr1'] + d6['d6nr2'] + d6['d6nr3'] + d6['d6nr4'] + d6['d6nr5'] + d6['d6nr6']\n",
    "total_nz6 = d6['d6nz1'] + d6['d6nz2'] + d6['d6nz3'] + d6['d6nz4'] + d6['d6nz5'] + d6['d6nz6']\n",
    "total_ng7 = d7['d7ng1'] + d7['d7ng2'] + d7['d7ng3'] + d7['d7ng4'] + d7['d7ng5'] + d7['d7ng6']\n",
    "total_nr7 = d7['d7nr1'] + d7['d7nr2'] + d7['d7nr3'] + d7['d7nr4'] + d7['d7nr5'] + d7['d7nr6']\n",
    "total_nz7 = d7['d7nz1'] + d7['d7nz2'] + d7['d7nz3'] + d7['d7nz4'] + d7['d7nz5'] + d7['d7nz6']\n",
    "total_ng9 = d9['d9ng1'] + d9['d9ng2'] + d9['d9ng3'] + d9['d9ng4'] + d9['d9ng5'] + d9['d9ng6']\n",
    "total_nr9 = d9['d9nr1'] + d9['d9nr2'] + d9['d9nr3'] + d9['d9nr4'] + d9['d9nr5'] + d9['d9nr6']\n",
    "total_nz9 = d9['d9nz1'] + d9['d9nz2'] + d9['d9nz3'] + d9['d9nz4'] + d9['d9nz5'] + d9['d9nz6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7bf28-6fe5-4788-ac8a-504a87f29613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:35.132470Z",
     "iopub.status.busy": "2023-09-15T04:21:35.131819Z",
     "iopub.status.idle": "2023-09-15T04:21:35.204198Z",
     "shell.execute_reply": "2023-09-15T04:21:35.202869Z",
     "shell.execute_reply.started": "2023-09-15T04:21:35.132411Z"
    }
   },
   "source": [
    "Now we add up he histograms of pixels with 3 or more exposures per brick per band g,r,z in each of the datasets DR6, DR7 & DR9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7253a-c0fc-48f4-82c5-2bcac9381ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge3_ng6 = d6['d6ng4'] + d6['d6ng5'] + d6['d6ng6']\n",
    "ge3_nr6 = d6['d6nr4'] + d6['d6nr5'] + d6['d6nr6']\n",
    "ge3_nz6 = d6['d6nz4'] + d6['d6nz5'] + d6['d6nz6']\n",
    "ge3_ng7 = d7['d7ng4'] + d7['d7ng5'] + d7['d7ng6'] \n",
    "ge3_nr7 = d7['d7nr4'] + d7['d7nr5'] + d7['d7nr6'] \n",
    "ge3_nz7 = d7['d7nz4'] + d7['d7nz5'] + d7['d7nz6']\n",
    "ge3_ng9 = d9['d9ng4'] + d9['d9ng5'] + d9['d9ng6']\n",
    "ge3_nr9 = d9['d9nr4'] + d9['d9nr5'] + d9['d9nr6']\n",
    "ge3_nz9 = d9['d9nz4'] + d9['d9nz5'] + d9['d9nz6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c957210-799b-4451-8a20-c57be51fe232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:35.132470Z",
     "iopub.status.busy": "2023-09-15T04:21:35.131819Z",
     "iopub.status.idle": "2023-09-15T04:21:35.204198Z",
     "shell.execute_reply": "2023-09-15T04:21:35.202869Z",
     "shell.execute_reply.started": "2023-09-15T04:21:35.132411Z"
    }
   },
   "source": [
    "We then normalize to 1 to obtain a fraction of coverage per brick of each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d9fe5-a640-4149-9336-defe83bf4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing all sums to 1\n",
    "fraction_ng6 = ge3_ng6 / total_ng6\n",
    "fraction_nr6 = ge3_nr6 / total_nr6\n",
    "fraction_nz6 = ge3_nz6 / total_nz6\n",
    "fraction_ng7 = ge3_ng7 / total_ng7\n",
    "fraction_nr7 = ge3_nr7 / total_nr7\n",
    "fraction_nz7 = ge3_nz7 / total_nz7\n",
    "fraction_ng9 = ge3_ng9 / total_ng9\n",
    "fraction_nr9 = ge3_nr9 / total_nr9\n",
    "fraction_nz9 = ge3_nz9 / total_nz9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d8a1e-0119-497c-bfc0-baca935a8bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:35.132470Z",
     "iopub.status.busy": "2023-09-15T04:21:35.131819Z",
     "iopub.status.idle": "2023-09-15T04:21:35.204198Z",
     "shell.execute_reply": "2023-09-15T04:21:35.202869Z",
     "shell.execute_reply.started": "2023-09-15T04:21:35.132411Z"
    }
   },
   "source": [
    "Let's build the conditions to count as valid values in each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5619db-b874-4e19-a775-9ec208598fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions to consider values\n",
    "cond6g = (d6['d6neg'] >= 3)  & (d6['nobjs'] >= nmin)  & (total_ng6 > npix) &  (fraction_ng6 >= 0.9)\n",
    "cond6r = (d6['d6ner'] >= 3)  & (d6['nobjs'] >= nmin)  & (total_nr6 > npix) &  (fraction_nr6 >= 0.9)\n",
    "cond6z = (d6['d6nez'] >= 3)  & (d6['nobjs'] >= nmin)  & (total_nz6 > npix) &  (fraction_nz6 >= 0.9)\n",
    "cond7g = (d7['d7neg'] >= 3)  & (d7['nobjs'] >= nmin)  & (total_ng7 > npix) &  (fraction_ng7 >= 0.9)\n",
    "cond7r = (d7['d7ner'] >= 3)  & (d7['nobjs'] >= nmin)  & (total_nr7 > npix) &  (fraction_nr7 >= 0.9)\n",
    "cond7z = (d7['d7nez'] >= 3)  & (d7['nobjs'] >= nmin)  & (total_nz7 > npix) &  (fraction_nz7 >= 0.9)\n",
    "cond9g = (d9['d9neg'] >= 3)  & (d9['nobjs'] >= nmin)  & (total_ng9 > npix) &  (fraction_ng9 >= 0.9)\n",
    "cond9r = (d9['d9ner'] >= 3)  & (d9['nobjs'] >= nmin)  & (total_nr9 > npix) &  (fraction_nr9 >= 0.9)\n",
    "cond9z = (d9['d9nez'] >= 3)  & (d9['nobjs'] >= nmin)  & (total_nz9 > npix) &  (fraction_nz9 >= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297435e-d4f6-45f5-b330-c64ee243dc83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:48.031774Z",
     "iopub.status.busy": "2023-09-15T04:21:48.031114Z",
     "iopub.status.idle": "2023-09-15T04:21:48.038100Z",
     "shell.execute_reply": "2023-09-15T04:21:48.036462Z",
     "shell.execute_reply.started": "2023-09-15T04:21:48.031710Z"
    }
   },
   "source": [
    "We stablish the bin range and size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f4654-e795-405e-aa09-5faf76a7ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bins = np.arange(22.5,26.0001,0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f750b-bce3-4833-850f-65a1bad930dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T18:19:34.195144Z",
     "iopub.status.busy": "2023-09-18T18:19:34.194490Z",
     "iopub.status.idle": "2023-09-18T18:19:34.253275Z",
     "shell.execute_reply": "2023-09-18T18:19:34.252408Z",
     "shell.execute_reply.started": "2023-09-18T18:19:34.195085Z"
    }
   },
   "source": [
    "Now we compute the 3 band histograms per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccf5e9-7636-4faf-80bc-348d3d431b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_g6,bins = np.histogram(d6['d6psfdg'][cond6g], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_r6,bins = np.histogram(d6['d6psfdr'][cond6r], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_z6,bins = np.histogram(d6['d6psfdz'][cond6z], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_g7,bins = np.histogram(d7['d7psfdg'][cond7g], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_r7,bins = np.histogram(d7['d7psfdr'][cond7r], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_z7,bins = np.histogram(d7['d7psfdz'][cond7z], bins=my_bins,range = (22.5, 26.0))\n",
    "cpc_g9,bins = np.histogram(d9['d9psfdg'][cond9g], bins=my_bins,range = (22.5, 29.0))\n",
    "cpc_r9,bins = np.histogram(d9['d9psfdr'][cond9r], bins=my_bins,range = (22.5, 29.0))\n",
    "cpc_z9,bins = np.histogram(d9['d9psfdz'][cond9z], bins=my_bins,range = (22.5, 29.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d1255-84cb-48dd-a58e-2aeb3ad709e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:21:55.028176Z",
     "iopub.status.busy": "2023-09-15T04:21:55.027528Z",
     "iopub.status.idle": "2023-09-15T04:21:55.034879Z",
     "shell.execute_reply": "2023-09-15T04:21:55.033359Z",
     "shell.execute_reply.started": "2023-09-15T04:21:55.028118Z"
    }
   },
   "source": [
    "We calculate a realistic center for our bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb8f2a-7cc5-47a6-944f-173b3e14e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = (bins[0:-1]+bins[1:])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65ed21-4937-4044-8925-0e8c8f2e185c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:22:00.021203Z",
     "iopub.status.busy": "2023-09-15T04:22:00.020529Z",
     "iopub.status.idle": "2023-09-15T04:22:00.034348Z",
     "shell.execute_reply": "2023-09-15T04:22:00.032778Z",
     "shell.execute_reply.started": "2023-09-15T04:22:00.021144Z"
    }
   },
   "source": [
    "Calculate the cumulative sum, maximum and the fraction of each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed23cd4-e02f-487c-aa37-67cfac63b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpcf_g1 = np.cumsum(cpc_g6)\n",
    "max_g6 = cpcf_g1.max()\n",
    "cpcf_g1 = cpcf_g1/max_g6\n",
    "cpcf_r1 = np.cumsum(cpc_r6)\n",
    "max_r6 = cpcf_r1.max()\n",
    "cpcf_r1 = cpcf_r1/max_r6\n",
    "cpcf_z1 = np.cumsum(cpc_z6)\n",
    "max_z6 = cpcf_z1.max()\n",
    "cpcf_z1 = cpcf_z1/max_z6\n",
    "\n",
    "cpcf_g2 = np.cumsum(cpc_g7)\n",
    "max_g7 = cpcf_g2.max()\n",
    "cpcf_g2 = cpcf_g2/max_g7\n",
    "cpcf_r2 = np.cumsum(cpc_r7)\n",
    "max_r7 = cpcf_r2.max()\n",
    "cpcf_r2 = cpcf_r2/max_r7\n",
    "cpcf_z2 = np.cumsum(cpc_z7)\n",
    "max_z7 = cpcf_z2.max()\n",
    "cpcf_z2 = cpcf_z2/max_z7\n",
    "\n",
    "cpcf_g3 = np.cumsum(cpc_g9)\n",
    "max_g9 = cpcf_g3.max()\n",
    "cpcf_g3 = cpcf_g3/max_g9\n",
    "cpcf_r3 = np.cumsum(cpc_r9)\n",
    "max_r9 = cpcf_r3.max()\n",
    "cpcf_r3 = cpcf_r3/max_r9\n",
    "cpcf_z3 = np.cumsum(cpc_z9)\n",
    "max_z9 = cpcf_z3.max()\n",
    "cpcf_z3 = cpcf_z3/max_z9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a658bd-b68e-4173-8491-cc72e01fc0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:22:07.028439Z",
     "iopub.status.busy": "2023-09-15T04:22:07.027821Z",
     "iopub.status.idle": "2023-09-15T04:22:07.336530Z",
     "shell.execute_reply": "2023-09-15T04:22:07.335212Z",
     "shell.execute_reply.started": "2023-09-15T04:22:07.028383Z"
    }
   },
   "source": [
    "Finally, we plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61c3ac-8d32-4300-9c12-256109e9dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "#fig, ax = plt.subplots()\n",
    "                       \n",
    "plt.figure(figsize=(9,8))\n",
    "plt.xlim(22.5,26.0)\n",
    "plt.ylim(0,1.)\n",
    "plt.xlabel('AB Magnitude', fontsize = 20)\n",
    "plt.ylabel('Cumulative fraction', fontsize = 20)\n",
    "#plt.Axes.tick_params(axis='both', direction = 'in')\n",
    "#ax.tick_params(axis='both', direction = 'in')\n",
    "plt.plot(centers,cpcf_g2, c='blue', label='DR7 g', lw=0.8)\n",
    "plt.plot(centers,cpcf_g1, c='blue', ls='dashed', label='DR6 g', lw=0.8)\n",
    "plt.plot(centers,cpcf_g3, c='blue', label='DR9 g', ls='solid', lw=2)\n",
    "\n",
    "plt.plot(centers,cpcf_r2, c='red', label='DR7 r', lw=0.8)\n",
    "plt.plot(centers,cpcf_r1, c='red', ls='dashed', label='DR6 r', lw=0.8)\n",
    "plt.plot(centers,cpcf_r3, c='red', label='DR9 r', ls='solid',lw=2)\n",
    "\n",
    "plt.plot(centers,cpcf_z2, c='purple', label='DR7 z', lw=0.8)\n",
    "plt.plot(centers,cpcf_z1, c='purple', ls='dashed', label='DR6 z', lw=0.8)\n",
    "plt.plot(centers,cpcf_z3, c='purple', label='DR9 z',ls='solid', lw=2)\n",
    "\n",
    "plt.legend(loc='lower right',frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c752fe71-750a-4ecd-a4e1-d0cc619d5a8d",
   "metadata": {},
   "source": [
    "The curves for DR6 & DR7 above are identical to the paper's plot.\n",
    "\n",
    "DR9 shows reaching deeper in most magnitudes, except in the very faint tail of each band, where it's more consistent and smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d34242-f12d-49a6-8d67-31531bf8fe37",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Fig16\"></a>\n",
    "## Fig 16 - Color-color Distribution by Type of Extended Objects\n",
    "In this section, we want to calculate 2d histograms of the color-color distribution, overlaying contours at different percentage levels of the number of sources in such distribution.\n",
    "\n",
    "We start by building the query to obtain the proper data.\n",
    "(TIP: Once a the query has been run with a limit of 100,000, repeat the next cell increasing the limit by 30K each time, so the sample size increases but the query won't take much longer since it uses the PostGRESQL cache. We can currently run the query with a limit of 500.000 hits under 5 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5510145-02c7-4563-9f37-a3ed9ff89f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 16 data query. \n",
    "# **IMPORTANT NOTE:** You have to run this cell and the following one a few times, and each time, \n",
    "# increase the LIMIT parameter in the query by around 120K until you reach around 550K-600K and \n",
    "# the data retrieval takes less than the maximum allowed time of 5 minutes. \n",
    "# The reason for that is \n",
    "# 1) The postgreSQL cache will reduce the time on each query run and\n",
    "# 2) we want the largest possible sample for better plots\n",
    "\n",
    "query_fig16a = (\"\"\"\n",
    "SELECT r_z, g_r, z_w1, type \n",
    "FROM nbdata.nb0068_lsdr7_tractor \n",
    "WHERE (type = 'EXP' or type = 'DEV' or type = 'PSF') AND\n",
    "(r_z != 'inf' and r_z != 'nan') AND\n",
    "(g_r != 'inf' and g_r != 'nan') AND\n",
    "(z_w1 != 'inf' and z_w1 != 'nan') AND\n",
    "random_id BETWEEN 11. AND 11.4\n",
    "LIMIT 150000\n",
    "\"\"\")\n",
    "print(query_fig16a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65d703-d9f0-425d-bb30-df6b9d1b8a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:34:54.025213Z",
     "iopub.status.busy": "2023-09-15T04:34:54.024568Z",
     "iopub.status.idle": "2023-09-15T04:35:03.902489Z",
     "shell.execute_reply": "2023-09-15T04:35:03.901113Z",
     "shell.execute_reply.started": "2023-09-15T04:34:54.025157Z"
    }
   },
   "source": [
    "Fetch the data from the __tractor__ table in DR7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31c454-0385-4a82-bbd1-cc03c030465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next line to be commented out once the tables are offline\n",
    "df16 = qc.query(sql=query_fig16a, fmt='pandas')\n",
    "# Next line to be uncommented once the tables are offline\n",
    "#color_type = Table.read(data16, format='pandas')\n",
    "\n",
    "df16[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18aa52-e6e1-4214-941d-2dc637a059ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:35:13.020652Z",
     "iopub.status.busy": "2023-09-15T04:35:13.019874Z",
     "iopub.status.idle": "2023-09-15T04:35:13.128858Z",
     "shell.execute_reply": "2023-09-15T04:35:13.127465Z",
     "shell.execute_reply.started": "2023-09-15T04:35:13.020577Z"
    }
   },
   "source": [
    "Checking the lenght and a few rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64721ba5-d993-4a2a-9f0a-70cd75b2c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33d038-bb59-46d4-8caf-e3c4e6aa5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16['g_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d55dc-608a-4eca-a15a-cddd6b62d4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T04:37:22.023873Z",
     "iopub.status.busy": "2023-09-15T04:37:22.023193Z",
     "iopub.status.idle": "2023-09-15T04:37:24.437205Z",
     "shell.execute_reply": "2023-09-15T04:37:24.435700Z",
     "shell.execute_reply.started": "2023-09-15T04:37:22.023813Z"
    }
   },
   "source": [
    "Here we finally plot our 2d histograms and distribution contours.\n",
    "\n",
    "Choosing the levels for the contours varies for one plot to the next. We wanted to represent them as close as we could to the original plot in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4806b07-9687-4e53-a49f-d8f7b808828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_panel(ax,x,y,xlims,ylims,xlabel='',ylabel='',levels=(0.05,0.09)):\n",
    "def plot_panel(ax,x,y,xlims,ylims,xlabel='',ylabel='',levels=()):\n",
    "    h,x_edges,y_edges,im = ax.hist2d(x,y, bins=400, norm = colors.Normalize(), cmap = plt.cm.Greys)\n",
    "    levels = np.array((levels)) * h.max()\n",
    "    x_centers = 0.5*(x_edges[1:] + x_edges[:-1])\n",
    "    y_centers = 0.5*(y_edges[1:] + y_edges[:-1])\n",
    "    ax.contour(x_centers,y_centers,h.T,origin='lower', levels=levels, colors=('k','k'), linewidths=0.9)\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.set_ylim(ylims)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "cond1 = (df16['type'] == 'PSF')\n",
    "cond2 = (df16['type'] == 'EXP')\n",
    "cond3 = (df16['type'] == 'DEV')\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize = (17, 14))\n",
    "plt.subplots_adjust(wspace = 0.25, hspace = 0.2)\n",
    "\n",
    "plot_panel(ax=axs[0,0],x=df16['g_r'][cond1],y=df16['r_z'][cond1],levels=np.array((0.022,0.055, 0.17)),xlims=(0,2.5),ylims=(-0.01,3),xlabel='',ylabel='r-z')\n",
    "plot_panel(ax=axs[0,1],x=df16['g_r'][cond2],y=df16['r_z'][cond2],levels=np.array((0.008,0.05, 0.2)),xlims=(0,2.5),ylims=(-0.01,3),xlabel='',ylabel='')\n",
    "plot_panel(ax=axs[0,2],x=df16['g_r'][cond3],y=df16['r_z'][cond3],levels=np.array((0.01,0.05, 0.2)),xlims=(0,2.5),ylims=(-0.01,3),xlabel='',ylabel='')\n",
    "plot_panel(ax=axs[1,0],x=df16['r_z'][cond1],y=df16['z_w1'][cond1],levels=np.array((-20,0.075)),xlims=(0,3),ylims=(-2,2.5),xlabel='r-z',ylabel='z-W1')\n",
    "plot_panel(ax=axs[1,1],x=df16['r_z'][cond2],y=df16['z_w1'][cond2],levels=np.array((-20,0.13)),xlims=(0,3),ylims=(-2,2.5),xlabel='r-z',ylabel='')\n",
    "plot_panel(ax=axs[1,2],x=df16['r_z'][cond3],y=df16['z_w1'][cond3],levels=np.array((0.0012, 0.08)),xlims=(0,3),ylims=(-2,2.5),xlabel='r-z',ylabel='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4abe64-8f9b-4274-b7fb-f97f4e7d16f3",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"resources\"></a>\n",
    "# Resources and references\n",
    "\n",
    "Dey, A. et al. (2019, AJ, 157, 168), \"Overview of the DESI Legacy Imaging Surveys\" https://ui.adsabs.harvard.edu/abs/2019AJ....157..168D/abstract"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DL,Py3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
