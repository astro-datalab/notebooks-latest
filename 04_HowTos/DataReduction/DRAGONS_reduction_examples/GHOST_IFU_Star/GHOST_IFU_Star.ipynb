{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941c702-6722-46ed-ab44-285010cd1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "__nbid__ = '00XX'\n",
    "__author__ = 'Brian Merino <brian.merino@noirlab.edu>, Vinicius Placco <vinicius.placco@noirlab.edu>'\n",
    "__version__ = '20241121' # yyyymmdd; version datestamp of this notebook\n",
    "__keywords__ = ['GHOST','Gemini','stars','DRAGONS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc5d10-66e1-4f22-88a4-1846e9f3c9ea",
   "metadata": {},
   "source": [
    "# Gemini GHOST XX Oph reduction using DRAGONS Python API\n",
    "***\n",
    "## Public archival data from ghost_tutorial - GS-ENG-GHOST-COM-3-915 (XX Oph)\n",
    "#### adapted from https://dragons.readthedocs.io/projects/ghost-drtutorial/en/release-3.2.x/index.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f75de4-ed74-4236-97b3-04b1a193ce8f",
   "metadata": {},
   "source": [
    "### Note: This notebook may take more than an hour to run. It may take more or less time if you work with a dataset different from the one used in this tutorial. The total running time depends on the number and variety of files you want to reduce.\n",
    "\n",
    "### If you want to run this notebook on your local machine, ensure your DRAGONS calibration database is correctly set up. To do so, make sure the calibrations section of ./dragons/dragonsrc looks like this:\n",
    "\n",
    "```\n",
    "[calibs]\n",
    "databases = ~/.dragons/dragons.db get store\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6381c1-8c86-4d70-b33c-4a52e4cec8b6",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Goals](#goals)\n",
    "* [Summary](#summary)\n",
    "* [Disclaimers and attribution](#disclaimer)\n",
    "* [Imports and setup](#imports)\n",
    "* [About the dataset](#About)\n",
    "* [Prepare the working directory](#Prepare)\n",
    "* [Downloading data for reduction](#Downloading_Data)\n",
    "* [Create directory for raw files](#raw)\n",
    "* [Create File Lists](#File_Lists)\n",
    "* [Set up the DRAGONS logger](#DRAGONS_logger)\n",
    "* [Create update_list() and reduce_func()](#func)\n",
    "* [Select and reduce biases](#biases)\n",
    "* [Update list of files 1](#update_list_1)\n",
    "* [Select and reduce slit biases](#slit_biases)\n",
    "* [Update list of files 2](#update_list_2)\n",
    "* [Select and reduce red science biases](#red_science_biases)\n",
    "* [Select and reduce blue science biases](#blue_science_biases)\n",
    "* [Select and reduce red flat/arc biases](#red_flat_arc_biases)\n",
    "* [Select and reduce blue flat/arc biases](#blue_flat_arc_biases)\n",
    "* [Clean up working directory 1](#clean_up_1)\n",
    "* [Select and reduce master and slit flats](#master_flat_and_slit_flats)\n",
    "* [Update list of files 3](#update_list_3)\n",
    "* [Select and reduce slit flats](#slit_flats)\n",
    "* [Select and reduce red flats](#red_flats)\n",
    "* [Select and reduce blue flats](#blue_flats)\n",
    "* [Clean up working directory 2](#clean_up_2)\n",
    "* [Select and reduce arcs](#arcs)\n",
    "* [Update list of files 4](#update_list_4)\n",
    "* [Select and reduce slit viewer data](#slit_viewer)\n",
    "* [Select and reduce red arcs](#red_arcs)\n",
    "* [Select and reduce blue arcs](#blue_arcs)\n",
    "* [Select and reduce spectroscopic standard](#spec_standard)\n",
    "* [Update list of files 5](#update_list_5)\n",
    "* [Select and reduce standard slit viewer data](#standard_slit_viewer)\n",
    "* [Select and reduce red standard data](#red_standard)\n",
    "* [Select and reduce blue standard data](#blue_standard)\n",
    "* [Clean up working directory 3](#clean_up_3)\n",
    "* [Select and reduce science data](#science)\n",
    "* [Update list of files 6](#update_list_6)\n",
    "* [Select and reduce science slit-viewer data](#science_slit_viewer)\n",
    "* [Update list of files 7](#update_list_7)\n",
    "* [Select and reduce red science data](#red_science)\n",
    "* [Select and reduce blue science data](#blue_science)\n",
    "* [Plot reduced spectra](#Plot)\n",
    "* [Output 1D spectra](#write1DSpectra)\n",
    "* [Save plots of reduced spectra](#Save_plot)\n",
    "* [Make reduced spectra IRAF compatible](#IRAF_compatible)\n",
    "* [Clean up working directory 4](#clean_up_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b968c-1c2b-4552-bcaa-f64d01886f09",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "# Goals\n",
    "Showcase how to reduce GHOST spectroscopy data using the Gemini DRAGONS package on the Data Lab science platform using a custom DRAGONS kernel `\"DRAGONS-3.2.1 (Py3.10)\"`. The steps include downloading data from the Gemini archive, setting up the DRAGONS calibration service, processing biases, flats, and arcs, creating master flats and slit-flats, reducing the standards and science data, and finally creating the final reduced spectra for GHOST's red and blue arms. \n",
    "\n",
    "\n",
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary\n",
    "DRAGONS is a Python-based astronomical data reduction platform written by the Gemini Science User Support Department. It can currently be used to reduce imaging data from Gemini instruments GMOS, NIRI, Flamingos 2, GSAOI, and GNIRS, as well as spectroscopic data taken with GHOST and GMOS in longslit mode. Linked [here](https://dragons.readthedocs.io/en/v3.2.1/) is a general list of guides, manuals, and tutorials about the use of DRAGONS.\n",
    "\n",
    "The DRAGONS kernel has been made available in the Data Lab environment, allowing users to access the routines without being dependent on installing the software on their local machines. It is important to note that when a DRAGON command is executed, the output will be displayed inside the cell. Make sure to scroll through the output to ensure no errors are missed. \n",
    "\n",
    "In this notebook, we present an example of a DRAGONS Jupyter notebook that works in the Data Lab environment to reduce Gemini South GHOST blue:2x2 and red:2x2 spectroscopy data fully. This notebook will not present all of the details of the many options available to adjust or optimize the DRAGONS GHOST data reduction process; rather, it will just show one example of a standard reduction of a GHOST spectroscopic dataset. \n",
    "\n",
    "The data used in this notebook example is GHOST blue:2x2 and red:2x2 spectroscopy data from the Gemini archive of the star XX Oph from the GHOST commissioning run. Because the data used is from a commissioning run, there is no program information available, but you can find more information about GHOST's red and blue IFUs on the [GHOST instrument page](https://www.gemini.edu/instrumentation/ghost).\n",
    "\n",
    "\n",
    "<a class=\"anchor\" id=\"disclaimer\"></a>\n",
    "# Disclaimer & attribution\n",
    "\n",
    "Disclaimers\n",
    "-----------\n",
    "Note that using the Astro Data Lab constitutes your agreement with our minimal [Disclaimers](https://datalab.noirlab.edu/disclaimers.php).\n",
    "\n",
    "Acknowledgments\n",
    "---------------\n",
    "If you use **Astro Data Lab** in your published research, please include the text in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the Astro Data Lab, which is part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "If you use **SPARCL jointly with the Astro Data Lab platform** (via JupyterLab, command-line, or web interface) in your published research, please include this text below in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the SPectra Analysis and Retrievable Catalog Lab (SPARCL) and the Astro Data Lab, which are both part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "In either case **please cite the following papers**:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Astro Data Lab overview: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411\n",
    "\n",
    "If you are referring to the Data Lab JupyterLab / Jupyter Notebooks, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097\n",
    "\n",
    "If publishing in a AAS journal, also add the keyword: `\\facility{Astro Data Lab}`\n",
    "\n",
    "And if you are using SPARCL, please also add `\\software{SPARCL}` and cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576\n",
    "\n",
    "The NOIRLab Library maintains [lists of proper acknowledgments](https://noirlab.edu/science/about/scientific-acknowledgments) to use when publishing papers using the Lab's facilities, data, or services.\n",
    "\n",
    "For this notebook specifically, please acknowledge:\n",
    "* DRAGONS publication: Labrie et al., [DRAGONS - Data Reduction for Astronomy from Gemini Observatory North and South](https://ui.adsabs.harvard.edu/abs/2019ASPC..523..321L/abstract), ASPC, 523, 321L \n",
    "\n",
    "* [DRAGONS open source software publication](https://zenodo.org/record/7776065#.ZDg5qOzMLUI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6af986-a038-4164-a9f9-8d35ce21a939",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imports\"></a>\n",
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f66156-8e55-405b-bf37-afd00515ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import astrodata\n",
    "import shutil\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import gemini_instruments\n",
    "from gempy.utils import logutils\n",
    "from gempy.adlibrary import dataselect\n",
    "from gempy.adlibrary import plotting\n",
    "\n",
    "from recipe_system import cal_service\n",
    "from recipe_system.reduction.coreReduce import Reduce\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9714b7c-cb16-4c9c-a90c-7b3b4517c73d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"About\"></a>\n",
    "# About the dataset\n",
    "\n",
    "The GHOST data used for this tutorial is of the star XX Oph. IFU-1 was used to obtain standard resolution of the star. The data was obtained during the commissioning run.\n",
    "\n",
    "The table below contains a summary of the dataset:\n",
    "\n",
    "| Observation Type | File name(s) | IFU, Binning, and Read Mode |\n",
    "| :--- | :--- | :---: |\n",
    "| Science | S20230416S0079 | blue:2x2, slow; red:2x2, medium |\n",
    "| Science bias | S20230417S0011-015 |  |\n",
    "| Science flats | S20230416S0047 | 1x1; blue:slow; red:medium |\n",
    "| Science Arcs | S20230416S0049-51 | 1x1; blue:slow; red:medium |\n",
    "| Flat biases <br> Arc Biases | S20230417S0036-40 | 1x1; blue:slow; red:medium |\n",
    "| Standard (CD -32 9927) | S20230416S0073 | blue:2x2, slow; red:2x2, medium |\n",
    "| Standard biases <br> Standard flats <br> Standard arc <br> Standard flat biases <br> Standard arc biases | Use science calibrations |\n",
    "| BPMs | bpm_20220601_ghost_blue_11_full_4amp.fits <br> bpm_20220601_ghost_red_11_full_4amp.fits |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31475af-f209-470a-bad5-2bdb38a14528",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Prepare\"></a>\n",
    "# Prepare the working directory\n",
    "\n",
    "If you have any intermediate files that were created from running this code in the past, you will need to remove them from your working directory. The cell below defines a clean-up function that will remove all the fits files from your working directory. This function will be called again at the end of the tutorial, leaving you with only the final product. \n",
    "\n",
    "By default, this function will delete all files in the working directory. If there are files that have been previously reduced that you would like to keep, set `save_reduced=1` when calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b5efd-e8c7-4554-a1b3-1d805725f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(save_reduced=0):\n",
    "    #Does the calibrations directory already exist?\n",
    "    caldb_Exist = os.path.exists('./calibrations') \n",
    "    reduced_dir = os.path.exists('./reduced') \n",
    "    \n",
    "    if caldb_Exist:\n",
    "        shutil.rmtree('./calibrations', ignore_errors=True)\n",
    "\n",
    "    #Remove existing log and list files.\n",
    "    work_dir_path = os.getcwd()\n",
    "    work_dir = os.listdir(work_dir_path)\n",
    "\n",
    "    for item in work_dir:\n",
    "        if item.endswith(\".log\") or item.endswith(\".list\"):\n",
    "            os.remove(os.path.join(work_dir_path, item))\n",
    "    \n",
    "    #Next, we will remove all the existing fits files, except for the previously reduced files, depending on what you set save_reduced to.\n",
    "    if save_reduced:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        save = dataselect.select_data(all_files_0, [], ['PROCESSED'])\n",
    "        \n",
    "        for s in save:\n",
    "            os.remove(os.path.join(work_dir_path,s))\n",
    "\n",
    "        #Move reduced files to save/ directory\n",
    "        if reduced_dir:\n",
    "            remain_files = os.listdir(work_dir_path)\n",
    "        \n",
    "            for item2 in remain_files:\n",
    "                if item2.endswith(\".dat\") or item2.endswith(\".pdf\") or item2.endswith(\".fits\") or item2.endswith(\".png\"):\n",
    "                    #Check if the file already exists in reduced/\n",
    "                    #If it does, delete it and replace it with the new copy\n",
    "                    if os.path.exists(work_dir_path+'/reduced/'+item2):\n",
    "                        os.remove(work_dir_path+'/reduced/'+item2)\n",
    "                        shutil.move(item2,work_dir_path+'/reduced/')\n",
    "\n",
    "                    else:\n",
    "                        shutil.move(item2,work_dir_path+'/reduced/')\n",
    "        \n",
    "        #Create save/ directory and move reduced files\n",
    "        else:\n",
    "            #Make save/ directory\n",
    "            os.mkdir(work_dir_path+'/reduced/')\n",
    "            remain_files = os.listdir(work_dir_path)\n",
    "        \n",
    "            for item3 in remain_files:\n",
    "                if item3.endswith(\".dat\") or item3.endswith(\".pdf\") or item3.endswith(\".fits\") or item3.endswith(\".png\"):\n",
    "                    shutil.move(item3,work_dir_path+'/reduced/')    \n",
    "\n",
    "    else:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        for a in all_files_0:\n",
    "            os.remove(os.path.join(work_dir_path,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fdaad3-1807-46de-93aa-6c9997af2edc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Downloading_Data\"></a>\n",
    "# Downloading the data\n",
    "\n",
    "Download the spectroscopic and calibration data from the Gemini archive to the current working directory. This step only needs to be executed once.\n",
    "\n",
    "If you run this notebook for the first time and need to download the dataset, set the variable \"download=True\". The notebook will not redownload the dataset if it is set to False. This will become particularly useful if you run the notebooks more than once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d13033-2c71-4965-a52f-d92716de351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# create file that lists FITS files to be downloaded\n",
    "echo \"\\\n",
    "https://archive.gemini.edu/file/S20230416S0047.fits\n",
    "https://archive.gemini.edu/file/S20230416S0049.fits\n",
    "https://archive.gemini.edu/file/S20230416S0050.fits\n",
    "https://archive.gemini.edu/file/S20230416S0051.fits\n",
    "https://archive.gemini.edu/file/S20230416S0073.fits\n",
    "https://archive.gemini.edu/file/S20230416S0079.fits\n",
    "https://archive.gemini.edu/file/S20230417S0011.fits\n",
    "https://archive.gemini.edu/file/S20230417S0012.fits\n",
    "https://archive.gemini.edu/file/S20230417S0013.fits\n",
    "https://archive.gemini.edu/file/S20230417S0014.fits\n",
    "https://archive.gemini.edu/file/S20230417S0015.fits\n",
    "https://archive.gemini.edu/file/S20230417S0036.fits\n",
    "https://archive.gemini.edu/file/S20230417S0037.fits\n",
    "https://archive.gemini.edu/file/S20230417S0038.fits\n",
    "https://archive.gemini.edu/file/S20230417S0039.fits\n",
    "https://archive.gemini.edu/file/S20230417S0040.fits\n",
    "https://archive.gemini.edu/file/bpm_20220601_ghost_blue_11_full_4amp.fits\n",
    "https://archive.gemini.edu/file/bpm_20220601_ghost_red_11_full_4amp.fits\\\n",
    "\" > ghost.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be79639-cbba-4503-9d18-abde66a7297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "download=\"True\"\n",
    "\n",
    "if [ $download == \"True\" ]; then\n",
    "    wget --no-check-certificate -N -q -i ghost.list\n",
    "\n",
    "else\n",
    "    echo \"Skipping download. To download the data set used in this notebook, set download=True.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b593d4ba-fce6-407f-a3bc-ddad43c8fd9a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"raw\"></a>\n",
    "# Create a directory for raw files\n",
    "### This tutorial will create a large number of intermediate files that will be temporarily stored in the working directory. To ensure none of the original data is lost, we will create a directory called raw to store the preliminary data safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a791cb9-e88d-4b35-b1f8-76bb40ac0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if raw exists\n",
    "path_string = os.getcwd()\n",
    "flag = os.path.isdir(path_string+'/raw')\n",
    "\n",
    "if flag:\n",
    "    #Remove existing /raw and its contents\n",
    "    #os.rmdir(path_string+'/raw')\n",
    "    shutil.rmtree(path_string+'/raw')\n",
    "\n",
    "    #Create fresh copy of /raw\n",
    "    os.mkdir('raw')\n",
    "\n",
    "else:\n",
    "    #Create fresh copy of /raw\n",
    "    os.mkdir('raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51955138-886d-4e0a-b677-e21d9a4970d3",
   "metadata": {},
   "source": [
    "# Move the raw files in new directory called raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d359d-4278-49da-97ab-370b9b95541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "mv *fits raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a994b-d4f9-40f6-acb8-eafecf509c9d",
   "metadata": {},
   "source": [
    "###### <a class=\"anchor\" id=\"File_Lists\"></a>\n",
    "# Create file lists\n",
    "\n",
    "This data set contains science and calibration frames. For some programs, it could have different observed targets and exposure times depending on how you organize your raw data. The DRAGONS data reduction pipeline does not organize the data for you. You have to do it. DRAGONS provides tools to help you with that.\n",
    "\n",
    "The first step is to create lists that will be used in the data reduction process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56161cf0-4f4b-41e8-9951-6d9171255c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('raw/S2023*.fits')\n",
    "all_files.append(glob.glob('raw/bpm*.fits')[0])\n",
    "all_files.append(glob.glob('raw/bpm*.fits')[1])\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c553e-aa6f-4dd5-99e5-1009a69e374e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"DRAGONS_logger\"></a>\n",
    "# Setting up the DRAGONS logger\n",
    "\n",
    "DRAGONS comes with a local calibration manager that uses the same calibration association rules as the Gemini Observatory Archive. This allows reduce to make requests to a local light-weight database for matching processed calibrations when needed to reduce a dataset.\n",
    "\n",
    "This tells the system where to put the calibration database. This database will keep track of the processed calibrations we will send to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4630d-2de5-49fd-84fa-d256f6a006ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logutils.config(file_name='ghost.log')\n",
    "caldb = cal_service.set_local_database()\n",
    "caldb.init(\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990307b9-71a5-4450-91d7-22a294e28a84",
   "metadata": {},
   "source": [
    "### Add the Bad Pixel Masks to the calibration database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5dc41-fc3c-4364-9daf-f1272c89a1d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caldb.add_cal(glob.glob('raw/bpm*.fits')[0])\n",
    "caldb.add_cal(glob.glob('raw/bpm*.fits')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1d2fe-cf05-42ac-83fc-5e9b05cbbf3b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"func\"></a>\n",
    "# update_list() and reduce_func()\n",
    "\n",
    "This notebook will require updating the list of files in your working directory and calling the reduce command several times. To reduce the repetitive text, we have created two functions that will cut down the number of lines included in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8762f-9323-4572-8493-c9fd9de24ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_list():\n",
    "    #Create a new file list that contains the intermediate files\n",
    "    #identify all of the files in the working directory\n",
    "    intermediate = os.listdir()\n",
    "    new_all_files = []\n",
    "\n",
    "    #Since os.listdir() returns all files in the working directory\n",
    "    #this loop will pick out only the fits files and add them to a list.\n",
    "    for i in intermediate:\n",
    "        if i[-5:] == '.fits':\n",
    "            new_all_files.append(i)\n",
    "    \n",
    "    print('%i files in the list.'%len(new_all_files))\n",
    "\n",
    "    return new_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3c788-8776-48a1-89bd-7107e7f4cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_func(files_list,uparms=None,recipename=None):\n",
    "    #Use DRAGONS' reduce function to reduce the provided list of files.\n",
    "    #By default, this function will use the default settings for reduce().\n",
    "    #uparms: This is a list of tuples with the primitive name and parameter in the first element and the value in the second e.g. [('stackFrames:operation', 'median')]. \n",
    "    #recipename: The name of the recipe to use e.g. 'makeIRAFCompatible'.\n",
    "    reduce = Reduce()\n",
    "    reduce.files.extend(files_list)\n",
    "\n",
    "    if uparms != None:\n",
    "        reduce.uparms = [uparms]\n",
    "    \n",
    "    if recipename!= None:\n",
    "        reduce.recipename = recipename\n",
    "    \n",
    "    reduce.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da7d68-ef56-473f-9033-d857dd6f9b06",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"biases\"></a>\n",
    "# Select and reduce biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9368f9-8bb0-497c-a711-7bac8041e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasbundles = dataselect.select_data(all_files, ['BIAS'], [])\n",
    "print(biasbundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d85654-1d2e-4553-96d3-0a9d90c2e847",
   "metadata": {},
   "source": [
    "## Use reduce_func() to reduce the biases\n",
    "\n",
    "When this cell is done running, three files will be created for each bias (science, flat, and arc). They will have the suffix *_blue001.fits, *_red001.fits, and *_slit.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bcfd3-fee8-4fa3-99bd-41808f826133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasbundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad016f4-3b0b-4b49-9c71-2d4659925905",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_1\"></a>\n",
    "# Update list\n",
    "\n",
    "DRAGONS' reduce() function creates a lot of intermediate files that are stored in the working directory. Before calling it again, we first need to update our list of files using update_list()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb75a5-64d8-4bc7-b6f8-fb4ecd71db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c98840-7017-4c9b-b2a7-7563678806c5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"slit_biases\"></a>\n",
    "# Now use dataselect to choose the slit biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebdc0a-0b5c-4e65-8bd7-dad7c188805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasslit = dataselect.select_data(new_all_files, ['BIAS','SLIT'])\n",
    "print(biasslit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e746361-a3b6-4c6a-b3f5-e484e3dd02bf",
   "metadata": {},
   "source": [
    "## Reduce the slit biases.\n",
    "\n",
    "When done running, a new file will be created called S20230417S0040_slit_bias.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdac1fb-1c4f-4ce7-93b9-cfecc8d38534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasslit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd742f-9de5-4418-b962-bbd858651b8c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_2\"></a>\n",
    "# Once again, update the list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61486074-f2a4-4724-b438-8175b3c43268",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files2 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564370a4-2eae-4b2c-b400-9550bcdfca56",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_science_biases\"></a>\n",
    "# Use dataselect to choose the red science biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605f88b-20ab-467c-bde9-d77cef2c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"binning==\\'2x2\\'\"\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "biasredsci = dataselect.select_data(new_all_files2, ['BIAS', 'RED'], [], parsed_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68162881-2526-472d-a295-a2744ab7167a",
   "metadata": {},
   "source": [
    "# Reduce the red science biases.\n",
    "\n",
    "Once done running, a new file called S20230417S0012_red001_bias.fits will exist in the working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6fd52-b6ed-42c4-87fd-3add7b07c9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasredsci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263eb21-fc93-42d4-b6ba-8fd34733710f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_science_biases\"></a>\n",
    "# Select the blue science biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04dc6c-6bbb-4568-b043-95598c752640",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = 'binning==\\'2x2\\''\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "biasbluesci = dataselect.select_data(new_all_files2, ['BIAS','BLUE'], [], parsed_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978bd97-498d-445a-b2b9-4d8c1e008b2c",
   "metadata": {},
   "source": [
    "# Reduce the blue science biases.\n",
    "\n",
    "A single file called S20230417S0011_blue001_bias.fits will be created after running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66021b-570f-452f-aeb5-3b9874664a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasbluesci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2171f-08f1-49a0-baf1-d4292a4a626c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_flat_arc_biases\"></a>\n",
    "# Select the red flat/arc biases and reduce them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f22ba-3a9e-4cfb-bd77-b9aac31ced87",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = 'binning==\\'1x1\\''\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "biasredflatarc = dataselect.select_data(new_all_files2, ['BIAS','RED'], [], parsed_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c13a84-7275-4ad3-bdae-78664c344342",
   "metadata": {},
   "source": [
    "Running the following cell will create a new file called S20230417S0038_red001_bias.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4068c-b675-400f-b7b3-ce6ab7a71d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasredflatarc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5078c6-844e-415b-8b6b-e5543253a43a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_flat_arc_biases\"></a>\n",
    "# Select the blue flat/arc biases and reduce them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d34dd-7c11-436a-9bd8-b63f45f318be",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = 'binning==\\'1x1\\''\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "biasblueflatarc = dataselect.select_data(new_all_files2, ['BIAS','BLUE'], [], parsed_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77eff9-4407-4b1c-98e2-885dc16c8565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T20:28:42.397003Z",
     "iopub.status.busy": "2024-12-06T20:28:42.396733Z",
     "iopub.status.idle": "2024-12-06T20:28:42.400975Z",
     "shell.execute_reply": "2024-12-06T20:28:42.400488Z",
     "shell.execute_reply.started": "2024-12-06T20:28:42.396986Z"
    }
   },
   "source": [
    "Running the following cell will create a new file called S20230417S0039_blue001_bias.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940e9e1-ad7a-4c65-91fa-d3f2cbfa9a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(biasblueflatarc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270893d8-bd66-431e-b208-f246f054677e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean_up_1\"></a>\n",
    "# Clean-up\n",
    "\n",
    " GHOST reduction creates a lot of, often big, files in the working directory. It is recommended to clean up between each reduction phase. If you want to save the intermediate files, move them (mv) somewhere else. In this tutorial, we will simply delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c5c51-4da5-42dd-a86f-0aa319d7152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm *fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8780c8-2cd1-4754-9dd7-cddf56ab461e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"master_flat_and_slit_flats\"></a>\n",
    "# Master Flats and Slit-flats\n",
    "### Debundle the flats then reduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d560058-bdbb-467d-a7f4-20e1461cbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatbundles = dataselect.select_data(all_files, ['FLAT'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa905110-40d3-43db-b248-edaa9e613dbc",
   "metadata": {},
   "source": [
    "Running this cell will generate 11 files form the science flat S20230416S0047.fits. Five will have the suffix _blue00*.fits, five will have the suffix _red00*.fits, and the remainder will have the suffix _slit.fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9f829-7a2a-4d79-a93f-00753d321ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(flatbundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2d5ab-659a-4209-b283-077d91b4c22d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_3\"></a>\n",
    "# Update the list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f0fd3-2778-4f1e-bb52-cafef537c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files3 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44271bde-0dab-44e4-9fe3-515d3d1dd32f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"slit_flats\"></a>\n",
    "# Select the slit-flats and reduce them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db681449-00ba-4416-9da3-eba4d85e8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "slitflat = dataselect.select_data(new_all_files3, ['SLITFLAT'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d1305-bc94-40ee-95d0-b99c6d08dc1e",
   "metadata": {},
   "source": [
    "The following cell will create a single file called S20230416S0047_slit_slitflat.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83e801-1260-49a2-ba1a-c34a7d8b3b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(slitflat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe493dda-c1ba-4a6c-9d75-dc3ecb1cd983",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_flats\"></a>\n",
    "# Select and reduce the red flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497235b-42ce-45e6-984b-91ab71beadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatred = dataselect.select_data(new_all_files3, ['FLAT','RED'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55502697-fb3c-4292-a3b7-d254f1cda915",
   "metadata": {},
   "source": [
    "Running the next cell will also create a single file called S20230416S0047_red002_flat.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7173c9-2b0c-40c9-b96d-a643098aca1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(flatred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb5930-a4fd-4696-a520-6a9f5d649a3b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_flats\"></a>\n",
    "# Select and reduce the blue flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d64d4e-e45e-49ff-b8bb-50a039b3b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatblue = dataselect.select_data(new_all_files3, ['FLAT','BLUE'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0e8f8-4d75-4a8b-88e1-dbb25358aa64",
   "metadata": {},
   "source": [
    "The following cell will create a file called S20230416S0047_blue001_flat.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fad40-9b59-4713-a2bb-d1d0d8764335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(flatblue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31461ce6-e27f-46d9-9504-4a35c99a5922",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean_up_2\"></a>\n",
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e46034-188d-4a64-8457-41262c201d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm *fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27471604-8a19-42e1-8341-e92548e3ea6b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"arcs\"></a>\n",
    "# Arcs\n",
    "### Debundle the arcs and reduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc571cbd-4e39-4650-a42b-fe27d8b47fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcbundles = dataselect.select_data(all_files, ['ARC'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd628bf-cdee-4925-8873-c1b4332d2b3b",
   "metadata": {},
   "source": [
    "Running the next cell will create 9 files, three for each of the science arcs. Three will have the suffix _blue001.fits, three will have the suffix _red001.fits, and the remaining three will have the suffix _slit.fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9489051-474b-4806-aa94-c6698c765bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(arcbundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0210ff-d10c-44e2-8b12-33d7a657c617",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_4\"></a>\n",
    "# Update the list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a351b-d602-4208-ae9c-076789d20ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files4 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdfc143-73bd-4680-8855-536e59f3ace9",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"slit_viewer\"></a>\n",
    "# Select and reduce the slit-viewer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d52ada-7eb4-4cc6-aaa8-e0769e30716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcslit_1 = dataselect.select_data(new_all_files4, ['ARC','SLIT'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50678030-8f63-4456-ba52-a23de4443a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original tutorial orders their lists numerically by default, while this version does not.\n",
    "#A few lines of code have been added here to manually order the list.\n",
    "arcslit_1.sort()\n",
    "arcslit_2 = [arcslit_1[0]]\n",
    "print(arcslit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3750da-2456-42ee-892d-d82bff8ebb3d",
   "metadata": {},
   "source": [
    "The following cell will return a single file called S20230416S0049_slit_slit.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70d3f4-5fc3-4dc0-b490-3b4b7dabc89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(arcslit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84780f43-be55-4590-9b33-66e1d9aab0f9",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_arcs\"></a>\n",
    "# Select and reduce the red arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850523a-0af4-4dac-a1e6-2cb8a2a8bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcred = dataselect.select_data(new_all_files4, ['ARC','RED'], [])\n",
    "arcred.sort()\n",
    "arcred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097581b-9212-4d9f-8554-756437993c83",
   "metadata": {},
   "source": [
    "The following cell will create a file called S20230416S0049_red001_arc.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de35be-c6ce-43b4-a44c-2f421228b5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(arcred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36e7ce-7913-4bcd-9cac-f2866a846659",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_arcs\"></a>\n",
    "# Select and reduce the blue arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4065d83-c241-454e-8b98-b636642eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcblue = dataselect.select_data(new_all_files4, ['ARC','BLUE'], [])\n",
    "arcblue.sort()\n",
    "arcblue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd2679-90cd-455a-99bc-eff822d394db",
   "metadata": {},
   "source": [
    "The following cell will also create a single file called S20230416S0049_blue001_arc.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5aea95-6a16-4e39-9caa-90f4fad6dd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(arcblue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2aadc5-59f4-4ef0-b2f3-d6de791a75e0",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean_up_3\"></a>\n",
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45be17-a7ab-4dbc-9342-53db81a2335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm *fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a038983-c1ea-4235-9e78-79a1130c3082",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"spec_standard\"></a>\n",
    "# Spectroscopic Standard\n",
    "### Debundle the standards and reduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bb16b-044f-4750-8d70-1899d7eb4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"object=='CD -32 9927'\"\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "stdbundles = dataselect.select_data(all_files, [], [], parsed_expr)\n",
    "stdbundles.sort()\n",
    "stdbundles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02c60b-7546-473b-a6fa-6cd13fa87d7f",
   "metadata": {},
   "source": [
    "The next cell will create 5 files starting with the same name as the standard. One will have the suffix _blue001.fits, three will have the suffix _red00*.fits, and the final file will have the suffix _slit.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd2a13-1c13-4ad6-964f-03d1caf6117f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(stdbundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23417207-14b3-4aba-9e35-cf741ffde27f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_5\"></a>\n",
    "# Update the list of files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae3b91-1ebe-44db-ab1e-76efbcf21e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files5 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf441a-c0d1-4067-ae95-cce2c3cd197a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"standard_slit_viewer\"></a>\n",
    "# Select the slit-viewer standard data and reduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc4984-7658-4a75-a05e-d496a53e1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdslit = dataselect.select_data(new_all_files5, ['SLIT'], [])\n",
    "stdslit.sort()\n",
    "stdslit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b4b4f-cf28-4aa3-aa85-784f9a683ddd",
   "metadata": {},
   "source": [
    "Unlike the previous cells, the following cell will create four new fits files, and a pdf. The pdf will have the suffix _slit_slitflux. One fits file will have the suffix _slit_blue001_slit.fits and the remaining three will have the suffix _slit_red00*_slit.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3bb80d-9f42-475f-ac7e-aa98b030a4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(stdslit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd19e09-1e47-4892-aafd-302813bfc3e7",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_standard\"></a>\n",
    "# Select the red standard star data and reduce it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313aa461-a831-4e60-861c-f81597833f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdred = dataselect.select_data(new_all_files5, ['RED'], [])\n",
    "stdred.sort()\n",
    "stdred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd45cc-0344-4456-8929-1721d43b300f",
   "metadata": {},
   "source": [
    "Running the following cell will generate a file called S20230416S0073_red001_standard.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bf239-f1bc-4582-b233-f812049ce1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(stdred,uparms=('scaleCountsToReference:tolerance',1),recipename='reduceStandard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3993a36-ea26-4a2c-946e-f4fc6c82d38d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_standard\"></a>\n",
    "# Select the blue standard star data and reduce it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372b1b0-2922-4cef-be58-10638fded64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdblue = dataselect.select_data(new_all_files5, ['BLUE'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a6fd3-c55c-4519-9275-60fec540127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdblue.sort()\n",
    "stdblue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a642d33-a810-4b68-8d1c-790371d2b43c",
   "metadata": {},
   "source": [
    "The following cell will also produce a single file called S20230416S0073_blue001_standard.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd307fe-514a-46f3-9394-4c0e70d6f8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(stdblue,uparms=('scaleCountsToReference:tolerance',1),recipename='reduceStandard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4fd80-a087-418e-adc9-58e438648a9c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean_up_3\"></a>\n",
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce55399-21ca-4e12-a39f-eccbab6aaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm *fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5fa43-cdc9-4929-ba0d-ab5b2f0a1ac2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"science\"></a>\n",
    "# Science Frames\n",
    "### Debundle the science frames and reduce them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c84e7-e3b3-4a0b-8be2-bbbd1292b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"object=='XX Oph'\"\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "scibundles = dataselect.select_data(all_files, [], [],parsed_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3143e0e-5922-4752-8ebc-632c2e77a558",
   "metadata": {},
   "source": [
    "Running the next cell will create 5 files whose names will start with the name of the science file. One will have the suffix _blue001.fits, three will have the suffix _red00*.fits, and the final file will have the suffix _slit.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62155d2f-c778-4d00-81eb-816e94d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_func(scibundles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba0a20-25ae-4493-9131-9ab3d0a830eb",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_6\"></a>\n",
    "# Update the list of files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d25ce-9d6e-4899-83ab-279a688c5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files6 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753f26d-0d92-4f6f-912b-09275da350bc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"science_slit_viewer\"></a>\n",
    "# Select the slit-viewer science data and reduce it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ecedb-cb4c-42db-8193-2141c7fa8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scislit  = dataselect.select_data(new_all_files6, ['SLIT'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa8f4d-eb0b-442e-8e4e-909a94fde4c6",
   "metadata": {},
   "source": [
    "Like when reducing the science data, the following cell will create 5 files. One will have the suffix _slit_blue001_slit.fits, three will have the suffix _slit_red00*_slit.fits, and the last one will have the suffix _slit_slitflux.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512f23a-680e-47f1-9e6c-3c1253325dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(scislit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5957c-3523-45b3-a33a-a2a853a290f2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"update_list_7\"></a>\n",
    "# Update the list of files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e004e-bc20-44e7-9056-abf94b5ec252",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_files7 = update_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40e904-94df-4e38-be1c-47a9b5783f29",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"red_science\"></a>\n",
    "# Select and Reduce the red science frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b4764-e0c7-42cc-b6b5-fe7c79f78b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"object=='XX Oph'\"\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "scired = dataselect.select_data(new_all_files7, ['RED'], [])\n",
    "scired = np.sort(scired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8da98-bbd6-4e8b-948e-c5253f22a1c5",
   "metadata": {},
   "source": [
    "Running the following cell will create 4 files. One will have the suffix _red001_dragons.fits, and the other three will have the suffix _red00*_calibrated.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee54444-8d78-4f57-bb0e-5db1f00d79b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(scired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e5f2b-f8ac-4af6-a1fb-d9235e3b0955",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"blue_science\"></a>\n",
    "# Select and Reduce the blue science frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332eee5-d749-4461-ba68-455b40fc3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"object=='XX Oph'\"\n",
    "parsed_expr = dataselect.expr_parser(expression)\n",
    "sciblue = dataselect.select_data(new_all_files7, ['BLUE'], [])\n",
    "sciblue = np.sort(sciblue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d76c44-08ba-4de3-ae1f-379f92ba812f",
   "metadata": {},
   "source": [
    "Running the following cell will create two files. The first will have the suffix _blue001_calibrated.fits and the other will have the suffix _blue001_dragons.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b65a6-c52a-4060-bff5-5c4f2ae884a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_func(sciblue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f15278-9c18-49a2-b9e8-bbcf56e1621f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Plot\"></a>\n",
    "# Plot the reduced red and blue spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df8d53-4b10-4ecc-b35f-52e07dc7a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display S20230416S0079_red001_dragons.fits and S20230416S0079_blue001_dragons.fits\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(13,5))\n",
    "\n",
    "red_file = 'S20230416S0079_red001_dragons.fits'\n",
    "blue_file = 'S20230416S0079_blue001_dragons.fits'\n",
    "\n",
    "red_pf  = astrodata.open(red_file)\n",
    "blue_pf = astrodata.open(blue_file)\n",
    "\n",
    "red_flux  = red_pf[0].data\n",
    "blue_flux = blue_pf[0].data\n",
    "\n",
    "red_flux_array  = np.array(red_flux)\n",
    "blue_flux_array = np.array(blue_flux)\n",
    "\n",
    "red_wave  = red_pf[0].wcs(np.arange(red_flux.size)).astype(np.float32)\n",
    "blue_wave = blue_pf[0].wcs(np.arange(blue_flux.size)).astype(np.float32)\n",
    "\n",
    "# Convert the  from nm to  \n",
    "red_wave_array  = np.array(red_wave*10)\n",
    "blue_wave_array = np.array(blue_wave*10)\n",
    "\n",
    "ax1.plot(blue_wave_array,blue_flux_array,lw=0.4)\n",
    "ax1.set_xlim(3450,5450)\n",
    "ax1.set_ylim(-0.05*10**(-12),0.2*10**(-12))\n",
    "ax1.set_xlabel('Wavelength [$\\AA$]')\n",
    "ax1.set_ylabel('Flux [$W  m^{-2}  nm^{-1}$]')\n",
    "ax1.set_title(blue_file,size=11,fontweight='bold')\n",
    "\n",
    "ax2.plot(red_wave_array,red_flux_array,lw=0.4)\n",
    "ax2.set_xlim(5100,10700)\n",
    "ax2.set_ylim(-0.05*10**(-12),0.23*10**(-12))\n",
    "ax2.set_xlabel('Wavelength [$\\AA$]')\n",
    "ax2.set_ylabel('Flux [$W  m^{-2}  nm^{-1}$]')\n",
    "ax2.set_title(red_file,size=11,fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6b37f-94ad-440f-be0b-ed52aa49bc5d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"write1DSpectra\"></a>\n",
    "# Save 1D Spectra\n",
    "\n",
    "If you would like to save the finished spectra as text files instead of fits files, use the write1DSpectra recipe as demonstrated in the following two cells. \n",
    "\n",
    "Running the first cell will create two files. The first will be called S20230416S0079_red001_dragons_001.dat and the second will be called S20230416S0079_red001_dragons_002.dat.\n",
    "\n",
    "Running the second cell will also create two files. The first will be called S20230416S0079_blue001_dragons_001.dat and the second will be called S20230416S0079_blue001_dragons_002.dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289d6ab-a0bc-4569-a70d-58b6d601ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_to_1d = ['S20230416S0079_red001_dragons.fits']\n",
    "reduce_func(red_to_1d,recipename='write1DSpectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19553148-c4d6-49ad-9bfb-578f41183f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_to_1d = ['S20230416S0079_blue001_dragons.fits']\n",
    "reduce_func(blue_to_1d,recipename='write1DSpectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67c690-0127-4876-903a-b17e95bf97c6",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Save_plot\"></a>\n",
    "# Save reduced spectra\n",
    "\n",
    "If you want to save a PNG stamp plot of the reduced red and blue spectra, run the following cell. You also have the option to save the image in a different format, including SVG, eps, and PS, by replacing 'PNG' in the second to last line with your desired format. This code will save the red and blue spectra separately. One saved file will be called S20230416S0079_blue001_dragons.png, and the other will be called S20230416S0079_red001_dragons.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab3b43-ffa5-4a05-af25-07e37fd98348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .- Author: David Herrera - June 2024\n",
    "# Create a list of all DRAGONS reduced fits files in the current directory\n",
    "ls_fits = 'ls -1 *{blue,red}00?*_dragons.fits > dragons_fits.list'\n",
    "os.system(ls_fits)\n",
    "# Saving the list of DRAGONS reduced fits in a list\n",
    "fits_list = 'dragons_fits.list'\n",
    "\n",
    "# Open the list of fits files\n",
    "with open (fits_list, \"r\") as files:\n",
    "    fnames_list = [line.strip() for line in files.readlines()]\n",
    "\n",
    "# Read each fits file name\n",
    "for fname in fnames_list:\n",
    "    # Determine if it is a red or a blue spectrum\n",
    "    file = str(fname.strip())\n",
    "    if '_red' in file:\n",
    "        band = 'red' \n",
    "    else:\n",
    "        band = 'blue'\n",
    "    # Open and read the data from each FITS file\n",
    "    ad = astrodata.open(file)\n",
    "    flux = ad[0].data\n",
    "    lam = ad[0].wcs(np.arange(flux.size)).astype(np.float32)\n",
    "     \n",
    "    # Convert the  from nm to  \n",
    "    lambda_array = np.array(lam*10)\n",
    "    flux_array = np.array(flux)\n",
    " \n",
    "    # Define lambda ranges for each panel depending on the band\n",
    "    if band == 'red':\n",
    "        lambda_ranges = [(5370, 6330), (6270, 7230), (7170, 8130), (8070, 9030), (8970, 9930)]\n",
    "    else:\n",
    "        lambda_ranges = [(3790, 4110), (4090, 4410), (4390, 4710), (4690, 5010), (4990, 5310)]\n",
    "    # Create a figure and a set of 5 subplots\n",
    "    fig, axs = plt.subplots(len(lambda_ranges), 1, sharex=False, figsize=(10, 8))\n",
    " \n",
    "    # Plot data in each range\n",
    "    for i, (lam_min, lam_max) in enumerate(lambda_ranges):\n",
    "        # Filter data for the current range\n",
    "        mask = (lambda_array >= lam_min) & (lambda_array <= lam_max)\n",
    "        lambda_filtered = lambda_array[mask]\n",
    "        flux_filtered = flux_array[mask]\n",
    "     \n",
    "        if len(lambda_filtered) > 0 and len(flux_filtered) > 0:\n",
    "            # Plot the data\n",
    "            axs[i].plot(lambda_filtered, flux_filtered, c=band, lw='.6')\n",
    "            # Calculate the flux median of the range of flux in current range\n",
    "            flux_median = np.median(flux_filtered)\n",
    "            # Set the x-limits \n",
    "            axs[i].set_xlim(lam_min, lam_max)\n",
    "            # Set the y-limits for this particular panel\n",
    "            ylim=(-0.25 * flux_median, 2.5 * flux_median)\n",
    "            axs[i].set_ylim(ylim)\n",
    "            axs[i].set\n",
    "            # Hide tick values in y\n",
    "            #axs[i].set_yticks([])\n",
    "            # Handling ticks\n",
    "            axs[i].minorticks_on()\n",
    "            if band == 'red':\n",
    "                axs[i].set_xticks(np.arange(lam_min+30,lam_max+30,step=150))\n",
    "                axs[i].set_xticks(np.arange(lam_min+80,lam_max,step=50), minor = True)\n",
    "            axs[i].tick_params(axis = 'y', which='major', labelsize = 8)\n",
    "        else:\n",
    "            # Handle the case where no data points are in the range\n",
    "            axs[i].text(0.5, 0.5, 'No data in this range', transform=axs[i].transAxes,\n",
    "                     ha='center', va='center', color=band)\n",
    " \n",
    "        # Optionally, set y-label for each panel\n",
    "        #axs[i].set_yticks()\n",
    "        # Only y-label on the 3rd panel\n",
    "        if i == 2: axs[i].set_ylabel('Flux [$W  m^{-2}  nm^{-1}$]')\n",
    " \n",
    "    # Set x-axis label for the bottom plot\n",
    "    axs[-1].set_xlabel('()')\n",
    "    # Set title for the whole plot\n",
    "    fig.suptitle(file)\n",
    "    # Adjust layout to remove gaps between subplots\n",
    "    plt.tight_layout()\n",
    " \n",
    "    # Show the plot\n",
    "    #plt.show()\n",
    " \n",
    "    # Save plot in a file (it can be a png, svg, eps, ps)\n",
    "    fig.savefig(file.strip('fits') + 'png', dpi='figure', format='png', metadata=None, bbox_inches=None, pad_inches=0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ed48d-f3ef-419f-b557-468fe79e50b9",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"IRAF_compatible\"></a>\n",
    "# Make IRAF compatible\n",
    "\n",
    "This notebook's finished products conform to DRAGONS' fits standards which does not comply with what IRAF expects. If you would like the final reduced spectra to be compatible with IRAF, you can use the makeIRAFCompatible recipe as shown below. (Uncomment before running.)\n",
    "\n",
    "Running the first cell will create a file called S20230416S0079_red001_dragons_irafCompatible.fits.\n",
    "\n",
    "Running the second cell will create a file called S20230416S0079_blue001_dragons_irafCompatible.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4571b-8ec0-4f15-8dce-770260888013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_iraf = Reduce()\n",
    "# red_dragons_files = ['S20230416S0079_red001_dragons.fits']\n",
    "# reduce_iraf.files.extend(red_dragons_files)\n",
    "# reduce_iraf.recipename = 'makeIRAFCompatible'\n",
    "# reduce_iraf.runr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113edff-3d7f-4aee-a7cc-4ad5a042f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_iraf = Reduce()\n",
    "# blue_dragons_files = ['S20230416S0079_blue001_dragons.fits']\n",
    "# reduce_iraf.files.extend(blue_dragons_files)\n",
    "# reduce_iraf.recipename = 'makeIRAFCompatible'\n",
    "# reduce_iraf.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69369fd-eaad-44a9-a47d-9bd32c0f5b9b",
   "metadata": {},
   "source": [
    "This notebook has only used DRAGONS' default options. If you would like all the individual exposures to be reduced seperately, you can look into the <a href=\"https://dragons.readthedocs.io/projects/ghost-drtutorial/en/stable/ex1_ghost_stdonetarget_cmdline.html#alternative-data-products\">combineOrders()</a> command. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704656a-605d-4ee6-8735-8e550cd47561",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean_up_4\"></a>\n",
    "# Optional: Clean up working directory. (uncomment before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c9071-c125-4744-8b6f-5387d2ef9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_up(save_reduced=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e8435-a1a2-497a-a985-e2456d58312a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRAGONS-3.2.2 (DL,Py3.10.14)",
   "language": "python",
   "name": "dragons-3.2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
