{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__nbid__ = '0044'\n",
    "__author__ = 'Brian Merino <brian.merino@noirlab.edu>, Vinicius Placco <vinicius.placco@noirlab.edu>'\n",
    "__version__ = '20260203' # yyyymmdd; version datestamp of this notebook\n",
    "__keywords__ = ['niri','gemini','supernova','dragons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini NIRI supernova reduction using DRAGONS Python API\n",
    "***\n",
    "## Public archival data from niriimg_tutorial - GN-2015B-Q-31 (SN2014J)\n",
    "#### adapted from https://dragons.readthedocs.io/projects/niriimg-drtutorial/en/stable/ex1_niriim_extended_api.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Goals](#goals)\n",
    "* [Summary](#summary)\n",
    "* [Disclaimers and attribution](#disclaimer)\n",
    "* [Imports and setup](#imports)\n",
    "* [Prepare the working directory](#Prepare)\n",
    "* [About the dataset](#About)\n",
    "* [Downloading data for reduction](#Downloading_Data)\n",
    "* [Set up the DRAGONS logger](#DRAGONS_logger)\n",
    "* [Create File Lists](#File_Lists)\n",
    "* [Create Master Dark](#Master_dark)\n",
    "* [Bad Pixel Mask](#BPM)\n",
    "* [Create Master Flat Field](#Master_Flat)\n",
    "* [Standard Star](#Standard_Star)\n",
    "* [Reduce Science Images](#Reduce_Science)\n",
    "* [Display stacked final image](#Display_Image)\n",
    "* [Clean-up (optional)](#Clean-up)\n",
    "\n",
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "# Goals\n",
    "Showcase how to reduce NIRI imaging data using the Gemini DRAGONS package on the Data Lab science platform, using a custom DRAGONS kernel `\"DRAGONS-4.0.0 (DL,Py3.12)\"`. The steps include downloading data from the Gemini archive, setting up a DRAGONS calibration service, processing flats, darks, a bad pixel mask, and science frames, and creating a single combined stacked image.\n",
    "\n",
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary\n",
    "DRAGONS is a Python-based astronomical data reduction platform written by the Gemini Science User Support Department. It can currently be used to reduce imaging data from Gemini instruments GMOS, NIRI, Flamingos 2, GSAOI, and GNIRS, as well as spectroscopic data taken with GNIRS, GHOST, and GMOS in longslit mode. Linked <a href=\"https://dragons.readthedocs.io/en/stable/\">here</a> is a general list of guides, manuals, and tutorials about the use of DRAGONS.\n",
    "\n",
    "The DRAGONS kernel has been made available in the Data Lab environment, allowing users to access the routines without being dependent on installing the software on their local machines. \n",
    "\n",
    "In this notebook, we present an example of a DRAGONS Jupyter notebook that works in the Data Lab environment to reduce example Gemini North NIRI H-band imaging data fully. This notebook will not present all of the details of the many options available to adjust or optimize the DRAGONS NIRI data reduction process; instead, it will just show one example of a standard reduction of a NIRI imaging dataset. \n",
    "\n",
    "The data used in this notebook example is NIRI H-band imaging from the Gemini archive of the Supernova SN2014J from the Gemini North program \"<a href=\"https://archive.gemini.edu/programinfo/GN-2015B-Q-31\">SN2014J at very late phases</a>\", PI: Marten van Kerkwijk, program ID GN-2015B-Q-31."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"disclaimer\"></a>\n",
    "# Disclaimer & attribution\n",
    "\n",
    "Disclaimers\n",
    "-----------\n",
    "Note that using the Astro Data Lab constitutes your agreement with our minimal [Disclaimers](https://datalab.noirlab.edu/disclaimers.php).\n",
    "\n",
    "Acknowledgments\n",
    "---------------\n",
    "If you use **Astro Data Lab** in your published research, please include the text in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the Astro Data Lab, which is part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "If you use **SPARCL jointly with the Astro Data Lab platform** (via JupyterLab, command-line, or web interface) in your published research, please include this text below in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the SPectra Analysis and Retrievable Catalog Lab (SPARCL) and the Astro Data Lab, which are both part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "In either case **please cite the following papers**:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Astro Data Lab overview: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411\n",
    "\n",
    "If you are referring to the Data Lab JupyterLab / Jupyter Notebooks, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097\n",
    "\n",
    "If publishing in a AAS journal, also add the keyword: `\\facility{Astro Data Lab}`\n",
    "\n",
    "And if you are using SPARCL, please also add `\\software{SPARCL}` and cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576\n",
    "\n",
    "The NOIRLab Library maintains [lists of proper acknowledgments](https://noirlab.edu/science/about/scientific-acknowledgments) to use when publishing papers using the Lab's facilities, data, or services.\n",
    "\n",
    "For this notebook specifically, please acknowledge:\n",
    "* DRAGONS publication: Labrie et al., <a href=\"https://ui.adsabs.harvard.edu/abs/2019ASPC..523..321L/abstract\">\"DRAGONS - Data Reduction for Astronomy from Gemini Observatory North and South\"</a>, ASPC, 523, 321L \n",
    "\n",
    "* <a href=\"https://zenodo.org/record/7776065#.ZDg5qOzMLUI\">DRAGONS open source software publication</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imports\"></a>\n",
    "# Importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from gempy.adlibrary import dataselect\n",
    "from gempy.utils import logutils\n",
    "\n",
    "from recipe_system import cal_service\n",
    "from recipe_system.reduction.coreReduce import Reduce\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Prepare\"></a>\n",
    "# Prepare the working directory\n",
    "\n",
    "If you have any intermediate files that were created from running this code in the past, you will need to remove them from your working directory. The cell below defines a clean-up function that will remove all the fits files from your working directory. This function will be called again at the end of the tutorial, leaving you with only the final product. By default, this function will delete all files in the working directory. If there are files that have been previously reduced that you would like to keep, set `save_reduced=1` when calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(save_reduced=0):\n",
    "    #Does the calibrations directory already exist?\n",
    "    caldb_Exist = os.path.exists('./calibrations') \n",
    "    \n",
    "    if caldb_Exist:\n",
    "        shutil.rmtree('./calibrations', ignore_errors=True)\n",
    "\n",
    "    #Remove existing log and list files.\n",
    "    work_dir_path = os.getcwd()\n",
    "    work_dir = os.listdir(work_dir_path)\n",
    "\n",
    "    for item in work_dir:\n",
    "        if item.endswith(\".log\") or item.endswith(\".list\"):\n",
    "            os.remove(os.path.join(work_dir_path, item))\n",
    "    \n",
    "    #Next, we will remove all the existing fits files, except for the previously reduced files, depending on what you set save_reduced to.\n",
    "    if save_reduced:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        save = dataselect.select_data(all_files_0, [], ['PROCESSED'])\n",
    "        \n",
    "        for s in save:\n",
    "            os.remove(os.path.join(work_dir_path,s))\n",
    "\n",
    "    else:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        for a in all_files_0:\n",
    "            os.remove(os.path.join(work_dir_path,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(save_reduced=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"About\"></a>\n",
    "# About the dataset\n",
    "\n",
    "This is a NIRI imaging observation of an extended source, a galaxy showing as a dense field of stars. The observation sequence uses an offset to a nearby blank portion of the sky to monitor the sky levels since no area in the science observation is not \"contaminated\" by the galaxy.\n",
    "\n",
    "The calibrations we use for this example include:\n",
    "\n",
    "Darks for the science and sky offset frames.\n",
    "Flats, as a sequence of lamp-on and lamp-off exposures.\n",
    "Short darks to use with the flats to create a bad pixel mask.\n",
    "A set of standard star observations.\n",
    "\n",
    "| Observation Type | File name(s) | Purpose and Exposure (seconds) |\n",
    "| :--- | :--- | :---: |\n",
    "| Science | N20160102S0270-274 | on-target |\n",
    "| Science | N20160102S0275-279 | on-sky |\n",
    "| Science Darks | N20160102S0423-432 | 20 sec, like science |\n",
    "| Flats | N20160102S0373-382  | Lamp on |\n",
    "| Flats | N20160102S0363-372 | Lamp off |\n",
    "| Short Darks | N20160103S0463-472 |  |\n",
    "| Standard Star | N20160102S0295-299 |  |\n",
    "| BPM | bpm_20010317_niri_niri_11_full_1amp.fits |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Downloading_Data\"></a>\n",
    "# Downloading the data\n",
    "\n",
    "Downloading NIR images from the Gemini archive to the current working directory. This step only needs to be executed once.\n",
    "\n",
    "If you run this notebook for the first time and need to download the dataset, set the variable \"download=True\". The notebook will not redownload the dataset if it is set to False. This will become particularly useful if you run the notebooks more than once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# create file that lists FITS files to be downloaded\n",
    "echo \"\\\n",
    "http://archive.gemini.edu/file/N20160102S0270.fits\n",
    "http://archive.gemini.edu/file/N20160102S0271.fits\n",
    "http://archive.gemini.edu/file/N20160102S0272.fits\n",
    "http://archive.gemini.edu/file/N20160102S0273.fits\n",
    "http://archive.gemini.edu/file/N20160102S0274.fits\n",
    "http://archive.gemini.edu/file/N20160102S0275.fits\n",
    "http://archive.gemini.edu/file/N20160102S0276.fits\n",
    "http://archive.gemini.edu/file/N20160102S0277.fits\n",
    "http://archive.gemini.edu/file/N20160102S0278.fits\n",
    "http://archive.gemini.edu/file/N20160102S0279.fits\n",
    "http://archive.gemini.edu/file/N20160102S0423.fits\n",
    "http://archive.gemini.edu/file/N20160102S0424.fits\n",
    "http://archive.gemini.edu/file/N20160102S0425.fits\n",
    "http://archive.gemini.edu/file/N20160102S0426.fits\n",
    "http://archive.gemini.edu/file/N20160102S0427.fits\n",
    "http://archive.gemini.edu/file/N20160102S0428.fits\n",
    "http://archive.gemini.edu/file/N20160102S0429.fits\n",
    "http://archive.gemini.edu/file/N20160102S0430.fits\n",
    "http://archive.gemini.edu/file/N20160102S0431.fits\n",
    "http://archive.gemini.edu/file/N20160102S0432.fits\n",
    "http://archive.gemini.edu/file/N20160102S0363.fits\n",
    "http://archive.gemini.edu/file/N20160102S0364.fits\n",
    "http://archive.gemini.edu/file/N20160102S0365.fits\n",
    "http://archive.gemini.edu/file/N20160102S0366.fits\n",
    "http://archive.gemini.edu/file/N20160102S0367.fits\n",
    "http://archive.gemini.edu/file/N20160102S0368.fits\n",
    "http://archive.gemini.edu/file/N20160102S0369.fits\n",
    "http://archive.gemini.edu/file/N20160102S0370.fits\n",
    "http://archive.gemini.edu/file/N20160102S0371.fits\n",
    "http://archive.gemini.edu/file/N20160102S0372.fits\n",
    "http://archive.gemini.edu/file/N20160102S0373.fits\n",
    "http://archive.gemini.edu/file/N20160102S0374.fits\n",
    "http://archive.gemini.edu/file/N20160102S0375.fits\n",
    "http://archive.gemini.edu/file/N20160102S0376.fits\n",
    "http://archive.gemini.edu/file/N20160102S0377.fits\n",
    "http://archive.gemini.edu/file/N20160102S0378.fits\n",
    "http://archive.gemini.edu/file/N20160102S0379.fits\n",
    "http://archive.gemini.edu/file/N20160102S0380.fits\n",
    "http://archive.gemini.edu/file/N20160102S0381.fits\n",
    "http://archive.gemini.edu/file/N20160102S0382.fits\n",
    "http://archive.gemini.edu/file/N20160103S0463.fits\n",
    "http://archive.gemini.edu/file/N20160103S0464.fits\n",
    "http://archive.gemini.edu/file/N20160103S0465.fits\n",
    "http://archive.gemini.edu/file/N20160103S0466.fits\n",
    "http://archive.gemini.edu/file/N20160103S0467.fits\n",
    "http://archive.gemini.edu/file/N20160103S0468.fits\n",
    "http://archive.gemini.edu/file/N20160103S0469.fits\n",
    "http://archive.gemini.edu/file/N20160103S0470.fits\n",
    "http://archive.gemini.edu/file/N20160103S0471.fits\n",
    "http://archive.gemini.edu/file/N20160103S0472.fits\n",
    "http://archive.gemini.edu/file/N20160102S0295.fits\n",
    "http://archive.gemini.edu/file/N20160102S0296.fits\n",
    "http://archive.gemini.edu/file/N20160102S0297.fits\n",
    "http://archive.gemini.edu/file/N20160102S0298.fits\n",
    "http://archive.gemini.edu/file/N20160102S0299.fits\n",
    "http://archive.gemini.edu/file/bpm_20010317_niri_niri_11_full_1amp.fits\\\n",
    "\" > niri.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "download=\"True\"\n",
    "\n",
    "if [ $download == \"True\" ]; then\n",
    "    wget --no-check-certificate -N -q -i niri.list\n",
    "\n",
    "else\n",
    "    echo \"Skipping download. To download the data set used in this notebook, set download=True.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"DRAGONS_logger\"></a>\n",
    "# Setting up the DRAGONS logger\n",
    "\n",
    "DRAGONS comes with a local calibration manager that uses the same calibration association rules as the Gemini Observatory Archive. This allows reduce to make requests to a local light-weight database for matching processed calibrations when needed to reduce a dataset.\n",
    "\n",
    "This tells the system where to put the calibration database. This database will keep track of the processed calibrations we will send to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logutils.config(file_name='niri_data_reduction.log')\n",
    "caldb = cal_service.set_local_database()\n",
    "caldb.init(\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a list of all the FITS files in the directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('N2016*[0-9].fits')\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"File_Lists\"></a>\n",
    "# Create file lists\n",
    "\n",
    "This data set contains science and calibration frames. For some programs, it could have different observed targets and exposure times depending on how you organize your raw data.\n",
    "\n",
    "The DRAGONS data reduction pipeline does not organize the data for you. You have to do it. DRAGONS provides tools to help you with that.\n",
    "\n",
    "The first step is to create input file lists. The tool \"dataselect\" helps with that. It uses Astrodata tags and \"descriptors\" to select the files and send the filenames to a text file that can then be fed to \"reduce\". (See the [Astrodata User Manual](https://dragons.readthedocs.io/_/downloads/astrodata-user-manual/en/v2.1.0/pdf/) for information about Astrodata.)\n",
    "\n",
    "**Two lists for the darks**\n",
    "\n",
    "We have two sets of darks: one set for the science frames, the 20-second darks, and another for making the BPM, the 1-second darks. We will create two lists.\n",
    "\n",
    "If you did not know the exposure times for the darks, you could have used a combination of \"dataselect\" to select all the darks (tag DARK) and feed that list to \"showd\" to show descriptor values, in this case, exposure_time. (See the descriptors page for a complete list.)\n",
    "\n",
    "**A list for the flats**\n",
    "\n",
    "The flats are a sequence of lamp-on and lamp-off exposures. We just send all of them to one list.\n",
    "\n",
    "**A list for the standard star**\n",
    "\n",
    "The standard stars at Gemini are normally taken as partner calibration.\n",
    "\n",
    "**A list for the science observations**\n",
    "\n",
    "The science frames are all the IMAGE non-FLAT frames that are also not the standard. Since flats are tagged FLAT and IMAGE, we must exclude the FLAT tag.\n",
    "\n",
    "\n",
    "You can see the observation_class of all the data using \"showd\". Here, we will print the object name, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darks1s = dataselect.select_data(\n",
    "    all_files, ['DARK'], [],\n",
    "    dataselect.expr_parser('exposure_time==1'))\n",
    "\n",
    "darks20s = dataselect.select_data(\n",
    "    all_files, ['DARK'], [],\n",
    "    dataselect.expr_parser('exposure_time==20'))\n",
    "\n",
    "flats = dataselect.select_data(all_files, ['FLAT'])\n",
    "\n",
    "stdstar = dataselect.select_data(\n",
    "    all_files, [], [],\n",
    "    dataselect.expr_parser('object==\"FS 17\"'))\n",
    "\n",
    "target = dataselect.select_data(\n",
    "    all_files, ['IMAGE'], ['FLAT'],\n",
    "    dataselect.expr_parser('object!=\"FS 17\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Master_dark\"></a>\n",
    "# Create master dark\n",
    "\n",
    "We first create the master dark for the science target, then add it to the calibration database. The name of the output master dark, N20160102S0423_dark.fits, is written on the screen at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_darks = Reduce()\n",
    "reduce_darks.files.extend(darks20s)\n",
    "reduce_darks.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"BPM\"></a>\n",
    "# Bad pixel mask\n",
    "\n",
    "Starting with DRAGONS v3.1, the static bad pixel masks (BPMs) are now handled as calibrations. They are downloadable from the archive instead of being packaged with the software. They are automatically associated like any other calibrations. This means that the user now must download the BPMs along with the other calibrations and add the BPMs to the local calibration manager.\n",
    "\n",
    "See [Getting Bad Pixel Masks from the archive](https://dragons.readthedocs.io/projects/niriimg-drtutorial/en/stable/05_tips_and_tricks.html#getbpm) in Tips and Tricks to learn about the various ways to get the BPMs from the archive.\n",
    "\n",
    "To add the BPM included in the data package to the local calibration database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bpm in dataselect.select_data(all_files, ['BPM']):\n",
    "    caldb.add_cal(bpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a supplemental, fresher BPM from the flats and recent short darks. That new BPM is later fed to \"[reduce](https://dragons.readthedocs.io/projects/recipe-system-users-manual/en/v4.0.0/reduce.html)\" as a user BPM to be combined with the static BPM. Using the static and fresh BPM from recent data leads to a better representation of the bad pixels. It is an optional but recommended step.\n",
    "\n",
    "The flats and the short darks are the inputs.\n",
    "\n",
    "The flats must be passed to the input list first to ensure that the recipe library associated with NIRI flats is selected. We will use the special recipe from that library called makeProcessedBPM.\n",
    "\n",
    "The BPM produced is named N20160102S0373_bpm.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_bpm = Reduce()\n",
    "reduce_bpm.files.extend(flats)\n",
    "reduce_bpm.files.extend(darks1s)\n",
    "reduce_bpm.recipename = 'makeProcessedBPM'\n",
    "reduce_bpm.runr()\n",
    "\n",
    "bpm = reduce_bpm.output_filenames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the Bad Pixel Masks to the calibration database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caldb.add_cal(bpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Master_Flat\"></a>\n",
    "# Master flat field\n",
    "\n",
    "A NIRI master flat is created from a series of lamp-on and lamp-off exposures. Each flavor is stacked, and then the lamp-off stack is subtracted from the lamp-on stack.\n",
    "\n",
    "The master flat will be saved with the suffix _flats.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_flats = Reduce()\n",
    "reduce_flats.files.extend(flats)\n",
    "reduce_flats.uparms = [('addDQ:user_bpm', bpm)]\n",
    "reduce_flats.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Standard_Star\"></a>\n",
    "# Standard star\n",
    "\n",
    "The standard star is reduced more or less like the science target (next section), except that dark frames are not obtained for standard star observations. Therefore, the dark correction needs to be turned off.\n",
    "\n",
    "The processed flat field we added to the local calibration database will be fetched automatically. The user BPM (optional but recommended) needs to be specified by the user.\n",
    "\n",
    "The reduced standard star image will be saved with the suffix _image.fits.\n",
    "\n",
    "NOTE: After running this cell, you may receive a warning regarding the Dark correction being turned off. You can ignore this warning as it will not affect the final product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_std = Reduce()\n",
    "reduce_std.files.extend(stdstar)\n",
    "reduce_std.uparms = [('addDQ:user_bpm', bpm)]\n",
    "reduce_std.uparms.append(('darkCorrect:do_cal', 'skip'))\n",
    "reduce_std.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Reduce_Science\"></a>\n",
    "# Reduce science images\n",
    "\n",
    "The science target is an extended source. We need to turn off the scaling of the sky because the target fills the field of view and does not represent a reasonable sky background. If scaling is not turned off in this case, it results in an over-subtraction of the sky frame.\n",
    "\n",
    "The sky frame comes from off-target sky observations. We feed the pipeline all the on-target and off-target frames. The software will split the on-target and the off-target appropriately.\n",
    "\n",
    "The master dark and flat will be retrieved automatically from the local calibration database. Again, the user BPM needs to be specified on the command line.\n",
    "\n",
    "The output stack units are in electrons (header keyword BUNIT=electrons). The output stack is stored in a multi-extension FITS (MEF) file. The science signal is in the \"SCI\" extension, the variance is in the \"VAR\" extension, and the data quality plane (mask) is in the \"DQ\" extension.\n",
    "\n",
    "The final reduced image will be saved with the suffix _image.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_target = Reduce()\n",
    "reduce_target.files.extend(target)\n",
    "reduce_target.uparms = [('addDQ:user_bpm', bpm)]\n",
    "reduce_target.uparms.append(('skyCorrect:scale_sky', False))\n",
    "reduce_target.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Display_Image\"></a>\n",
    "# Display the stacked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_file = \"N20160102S0271_image.fits\"\n",
    "hdu_list = fits.open(image_file)\n",
    "wcs = WCS(hdu_list[1].header)\n",
    "hdu_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fits.getdata(image_file, ext=1)\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.subplot(projection=wcs)\n",
    "plt.imshow(image_data,cmap='bone',norm=Normalize(vmin=1, vmax=50000),origin='lower')\n",
    "plt.xlabel('Right Ascension [hh:mm:ss]',fontsize=14,fontweight='bold')\n",
    "plt.ylabel('Declination [degree]',fontsize=14,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Clean-up\"></a>\n",
    "# Optional: remove raw data (uncomment lines before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_up(save_reduced=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRAGONS-4.0.0 (DL,Py3.12)",
   "language": "python",
   "name": "dragons-4.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
