{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__nbid__ = '0040'\n",
    "__author__ = 'Brian Merino <brian.merino@noirlab.edu>, Vinicius Placco <vinicius.placco@noirlab.edu>'\n",
    "__version__ = '20250912' # yyyymmdd; version datestamp of this notebook\n",
    "__keywords__ = ['gmos','gemini','stars','dragons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini GMOS starry field photometry reduction using DRAGONS Python API\n",
    "#### adapted from https://dragons.readthedocs.io/projects/gmosimg-drtutorial/en/stable/ex1_gmosim_starfield_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Table of contents\n",
    "* [Goals](#goals)\n",
    "* [Summary](#summary)\n",
    "* [Disclaimers and attribution](#disclaimer)\n",
    "* [Imports and setup](#imports)\n",
    "* [Prepare the working directory](#Prepare)\n",
    "* [About the dataset](#About)\n",
    "* [Downloading data for reduction](#Downloading_Data)\n",
    "* [Set up the DRAGONS logger](#DRAGONS_logger)\n",
    "* [Create File Lists](#File_Lists)\n",
    "* [Bad Pixel Mask](#BPM)\n",
    "* [Create Master Bias](#Master_Bias)\n",
    "* [Create Master Flat Field](#Master_Flat)\n",
    "* [Reduce Science Images](#Reduce_Science)\n",
    "* [Display stacked final image](#Display_Image)\n",
    "* [Clean-up (optional)](#Clean-up)\n",
    "\n",
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "# Goals\n",
    "Showcase how to reduce GMOS imaging data using the Gemini DRAGONS package on the Data Lab science platform using a custom DRAGONS kernel `\"DRAGONS-4.0.0 (DL,Py3.12)\"`. The steps include downloading data from the Gemini archive, setting up a DRAGONS calibration service, processing bias, flats, fringe, and science frames, and creating a single combined stacked image.\n",
    "\n",
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary\n",
    "DRAGONS is a Python-based astronomical data reduction platform written by the Gemini Science User Support Department. It can currently be used to reduce imaging data from Gemini instruments GMOS, NIRI, Flamingos 2, GSAOI, and GNIRS, as well as spectroscopic data taken with GNIRS, GHOST, and GMOS in longslit mode. Linked <a href=\"https://dragons.readthedocs.io/en/stable/\">here</a> is a general list of guides, manuals, and tutorials about the use of DRAGONS.\n",
    "\n",
    "The DRAGONS kernel has been made available in the Data Lab environment, allowing users to access the routines without being dependent on installing the software on their local machines. \n",
    "\n",
    "In this notebook, we present an example of a DRAGONS Jupyter notebook that works in the Data Lab environment to reduce example Gemini North GMOS I-band imaging data fully. This notebook will not present all of the details of the many options available to adjust or optimize the DRAGONS GMOS data reduction process; rather, it will just show one example of a standard reduction of a GMOS imaging dataset. \n",
    "\n",
    "The data used in this notebook example is GMOS I band imaging from the Gemini archive of a starry field from the Gemini North Hamamatsu CCD commissioning (Program: GN-2017A-SV-151).\n",
    "\n",
    "<a class=\"anchor\" id=\"disclaimer\"></a>\n",
    "# Disclaimer & attribution\n",
    "\n",
    "Disclaimers\n",
    "-----------\n",
    "Note that using the Astro Data Lab constitutes your agreement with our minimal [Disclaimers](https://datalab.noirlab.edu/disclaimers.php).\n",
    "\n",
    "Acknowledgments\n",
    "---------------\n",
    "If you use **Astro Data Lab** in your published research, please include the text in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the Astro Data Lab, which is part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "If you use **SPARCL jointly with the Astro Data Lab platform** (via JupyterLab, command-line, or web interface) in your published research, please include this text below in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the SPectra Analysis and Retrievable Catalog Lab (SPARCL) and the Astro Data Lab, which are both part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "In either case **please cite the following papers**:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Astro Data Lab overview: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411\n",
    "\n",
    "If you are referring to the Data Lab JupyterLab / Jupyter Notebooks, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097\n",
    "\n",
    "If publishing in a AAS journal, also add the keyword: `\\facility{Astro Data Lab}`\n",
    "\n",
    "And if you are using SPARCL, please also add `\\software{SPARCL}` and cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576\n",
    "\n",
    "The NOIRLab Library maintains [lists of proper acknowledgments](https://noirlab.edu/science/about/scientific-acknowledgments) to use when publishing papers using the Lab's facilities, data, or services.\n",
    "\n",
    "For this notebook specifically, please acknowledge:\n",
    "* DRAGONS publication: Labrie et al., <a href=\"https://ui.adsabs.harvard.edu/abs/2019ASPC..523..321L/abstract\">\"DRAGONS - Data Reduction for Astronomy from Gemini Observatory North and South\"</a>, ASPC, 523, 321L \n",
    "\n",
    "* <a href=\"https://zenodo.org/record/7776065#.ZDg5qOzMLUI\">DRAGONS open source software publication</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imports\"></a>\n",
    "# Importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from gempy.adlibrary import dataselect\n",
    "from gempy.utils import logutils\n",
    "\n",
    "from recipe_system import cal_service\n",
    "from recipe_system.reduction.coreReduce import Reduce\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Prepare\"></a>\n",
    "# Prepare the working directory\n",
    "\n",
    "If you have any intermediate files that were created from running this code in the past, you will need to remove them from your working directory. The cell below defines a clean-up function that will remove all the fits files from your working directory. This function will be called again at the end of the tutorial, leaving you with only the final product. By default, this function will delete all files in the working directory. If there are files that have been previously reduced that you would like to keep, set `save_reduced=1` when calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(save_reduced=0):\n",
    "    #Does the calibrations directory already exist?\n",
    "    caldb_Exist = os.path.exists('./calibrations') \n",
    "    \n",
    "    if caldb_Exist:\n",
    "        shutil.rmtree('./calibrations', ignore_errors=True)\n",
    "\n",
    "    #Remove existing log and list files.\n",
    "    work_dir_path = os.getcwd()\n",
    "    work_dir = os.listdir(work_dir_path)\n",
    "\n",
    "    for item in work_dir:\n",
    "        if item.endswith(\".log\") or item.endswith(\".list\"):\n",
    "            os.remove(os.path.join(work_dir_path, item))\n",
    "    \n",
    "    #Next, we will remove all the existing fits files, except for the previously reduced files, depending on what you set save_reduced to.\n",
    "    if save_reduced:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        save = dataselect.select_data(all_files_0, [], ['PROCESSED'])\n",
    "        \n",
    "        for s in save:\n",
    "            os.remove(os.path.join(work_dir_path,s))\n",
    "\n",
    "    else:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        for a in all_files_0:\n",
    "            os.remove(os.path.join(work_dir_path,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(save_reduced=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"About\"></a>\n",
    "# About the dataset\n",
    "\n",
    "The data used for this tutorial is a dithered sequence on a starry field.\n",
    "\n",
    "The table below contains a summary of the dataset:\n",
    "\n",
    "\n",
    "| Observation Type | File name(s) | Purpose and Exposure (seconds) |\n",
    "| :--- | :--- | :---: |\n",
    "| Science | N20170614S0201-205 | 10 s, i-band |\n",
    "| Bias | N20170613S0180-184 |  |\n",
    "| Bias | N20170615S0534-538 |  |\n",
    "| Twilight Flats | N20170702S0178-182 | 40 to 16 s, i-band |\n",
    "| BPM | bpm_20170306_gmos-n_Ham_22_full_12amp.fits |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Downloading_Data\"></a>\n",
    "# Downloading the data\n",
    "\n",
    "Downloading I-band images from the Gemini archive to the current working directory. This step only needs to be executed once.\n",
    "\n",
    "If you run this notebook for the first time and need to download the dataset, set the variable \"download=True\". The notebook will not redownload the dataset if it is set to False. This will become particularly useful if you run the notebooks more than once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# create file that lists FITS files to be downloaded\n",
    "echo \"\\\n",
    "http://archive.gemini.edu/file/N20170613S0180.fits\n",
    "http://archive.gemini.edu/file/N20170613S0181.fits\n",
    "http://archive.gemini.edu/file/N20170613S0182.fits\n",
    "http://archive.gemini.edu/file/N20170613S0183.fits\n",
    "http://archive.gemini.edu/file/N20170613S0184.fits\n",
    "http://archive.gemini.edu/file/N20170614S0201.fits\n",
    "http://archive.gemini.edu/file/N20170614S0202.fits\n",
    "http://archive.gemini.edu/file/N20170614S0203.fits\n",
    "http://archive.gemini.edu/file/N20170614S0204.fits\n",
    "http://archive.gemini.edu/file/N20170614S0205.fits\n",
    "http://archive.gemini.edu/file/N20170615S0534.fits\n",
    "http://archive.gemini.edu/file/N20170615S0535.fits\n",
    "http://archive.gemini.edu/file/N20170615S0536.fits\n",
    "http://archive.gemini.edu/file/N20170615S0537.fits\n",
    "http://archive.gemini.edu/file/N20170615S0538.fits\n",
    "http://archive.gemini.edu/file/N20170702S0178.fits\n",
    "http://archive.gemini.edu/file/N20170702S0179.fits\n",
    "http://archive.gemini.edu/file/N20170702S0180.fits\n",
    "http://archive.gemini.edu/file/N20170702S0181.fits\n",
    "http://archive.gemini.edu/file/N20170702S0182.fits\n",
    "http://archive.gemini.edu/file/bpm_20170306_gmos-n_Ham_22_full_12amp.fits\\\n",
    "\" > gmos_im_star.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "download=\"True\"\n",
    "\n",
    "if [ $download == \"True\" ]; then\n",
    "    wget --no-check-certificate -N -q -i gmos_im_star.list\n",
    "\n",
    "else\n",
    "    echo \"Skipping download. To download the data set used in this notebook, set download=True.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"DRAGONS_logger\"></a>\n",
    "# Setting up the DRAGONS logger\n",
    "\n",
    "DRAGONS comes with a local calibration manager that uses the same calibration association rules as the Gemini Observatory Archive. This allows reduce to make requests to a local light-weight database for matching processed calibrations when needed to reduce a dataset.\n",
    "\n",
    "This tells the system where to put the calibration database. This database will keep track of the processed calibrations we are going to send to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logutils.config(file_name='gmos_data_reduction.log')\n",
    "caldb = cal_service.set_local_database()\n",
    "caldb.init(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('N2017*[0-9].fits')\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"File_Lists\"></a>\n",
    "# Create file lists\n",
    "\n",
    "This data set contains science and calibration frames. For some programs, it could have different observed targets and exposure times depending on how you organize your raw data.\n",
    "\n",
    "The DRAGONS data reduction pipeline does not organize the data for you. You have to do it. DRAGONS provides tools to help you with that.\n",
    "\n",
    "The first step is to create lists that will be used in the data reduction process. For that, we use dataselect. Please refer to the [dataselect](https://dragons.readthedocs.io/projects/recipe-system-users-manual/en/stable/supptools/dataselect.html?highlight=dataselect) documentation for details regarding its usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_biases = dataselect.select_data(\n",
    "    all_files,\n",
    "    ['BIAS'],\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of flats**\n",
    "\n",
    "If your dataset has flats obtained with more than one filter, you can add the --expr 'filter_name==\"i\"' expression to get only the flats obtained within the i-band. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_flats = dataselect.select_data(\n",
    "     all_files,\n",
    "     ['FLAT'],\n",
    "     [],\n",
    "     dataselect.expr_parser('filter_name==\"i\"')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of science data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_science = dataselect.select_data(\n",
    "    all_files,\n",
    "    [],\n",
    "    ['CAL'],\n",
    "    dataselect.expr_parser('(observation_class==\"science\" and filter_name==\"i\")')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"BPM\"></a>\n",
    "## **Bad pixel mask**\n",
    "\n",
    "Starting with DRAGONS v3.1, the static bad pixel masks (BPMs) are now handled as calibrations. They are downloadable from the archive instead of being packaged with the software. They are automatically associated like any other calibrations. This means that the user now must download the BPMs along with the other calibrations and add the BPMs to the local calibration manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bpm in dataselect.select_data(all_files, ['BPM']):\n",
    "    caldb.add_cal(bpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Master_Bias\"></a>\n",
    "# Create a master bias\n",
    "We start the data reduction by creating a master bias for the science data. It can be created and added to the calibration database using the commands below. The master bias will have the name of the first bias with the suffix _bias.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_bias = Reduce()\n",
    "reduce_bias.files.extend(list_of_biases)\n",
    "reduce_bias.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Master_Flat\"></a>\n",
    "# Create a master flat field\n",
    "\n",
    "Twilight flat images are used to produce an imaging master flat and the result is added to the calibration database.\n",
    "\n",
    "The master flat will have the name of the first twilight flat file with the suffix _flat.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_flats = Reduce()\n",
    "reduce_flats.files.extend(list_of_flats)\n",
    "reduce_flats.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Reduce_Science\"></a>\n",
    "# Reduce science images\n",
    "\n",
    "Once our calibration files are processed and added to the database, we can run reduce on our science data.\n",
    "\n",
    "This command will generate bias and flat corrected files and will stack them. If a fringe frame is needed, this command will apply the correction. The stacked image will have the _stack suffix.\n",
    "\n",
    "The output stack units are in electrons (header keyword BUNIT=electrons). The output stack is stored in a multi-extension FITS (MEF) file. The science signal is in the \"SCI\" extension, the variance is in the \"VAR\" extension, and the data quality plane (mask) is in the \"DQ\" extension.\n",
    "\n",
    "Each reduced science image will have the original name with the suffix _image.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_science = Reduce()\n",
    "reduce_science.files.extend(list_of_science)\n",
    "reduce_science.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Display_Image\"></a>\n",
    "# Display the stacked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"N20170614S0201_image.fits\"\n",
    "hdu_list = fits.open(image_file)\n",
    "wcs = WCS(hdu_list[1].header)\n",
    "hdu_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fits.getdata(image_file, ext=1)\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(projection=wcs)\n",
    "plt.imshow(image_data,cmap='gray',norm=LogNorm(vmin=0.01, vmax=1000000),origin='lower')\n",
    "plt.xlabel('Right Ascension [hh:mm:ss]',fontsize=14,fontweight='bold')\n",
    "plt.ylabel('Declination [degree]',fontsize=14,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Clean-up\"></a>\n",
    "# Optional: remove duplicate calibrations and remove raw data (uncomment lines before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_up(save_reduced=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRAGONS-4.0.0 (DL,Py3.12)",
   "language": "python",
   "name": "dragons-4.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
